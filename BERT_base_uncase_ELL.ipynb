{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"mount_file_id":"1FGH3NxJkI5DEuQmm2ohAc-KYHXsdJXur","authorship_tag":"ABX9TyMr3EkcZHMtc2/6lxCMMz7Z"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"11d8b550829143a39c1fe70caf980c44":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e8cf93285d0b41edb115c25d3fda89e0","IPY_MODEL_05c72ab3efd24fe58d1e0d3380764d61","IPY_MODEL_6037ed36a38a4782a368f2b07937dd51"],"layout":"IPY_MODEL_c33ba02be0fa475b8956cf8df7cb78c0"}},"e8cf93285d0b41edb115c25d3fda89e0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4cc71a28f37c43669139610a0645fafe","placeholder":"​","style":"IPY_MODEL_78925eaa0b084505b742c0466c384adc","value":"Downloading: 100%"}},"05c72ab3efd24fe58d1e0d3380764d61":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6f11fc47f21744409abeb48bbe594b10","max":52,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a3afdcdb63a846bf9c0e1f1e9dbe7057","value":52}},"6037ed36a38a4782a368f2b07937dd51":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_593016b8011c457cb21282cf54c37b91","placeholder":"​","style":"IPY_MODEL_2b5b1fee222649a39091e1eab028197e","value":" 52.0/52.0 [00:00&lt;00:00, 570B/s]"}},"c33ba02be0fa475b8956cf8df7cb78c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4cc71a28f37c43669139610a0645fafe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"78925eaa0b084505b742c0466c384adc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6f11fc47f21744409abeb48bbe594b10":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a3afdcdb63a846bf9c0e1f1e9dbe7057":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"593016b8011c457cb21282cf54c37b91":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b5b1fee222649a39091e1eab028197e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"91416c2f7bd84dadb58d9f5895931871":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_33c27f6e0bca4c1a8c134566b772e800","IPY_MODEL_ee986a976ff9463a8740e74c2b2e14f8","IPY_MODEL_a69e0c238e744573bc6774bc757852eb"],"layout":"IPY_MODEL_8263342e6f6e493faa3a843544b6417a"}},"33c27f6e0bca4c1a8c134566b772e800":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8dace4bebedf47328364eb53a24c6a90","placeholder":"​","style":"IPY_MODEL_78f9b26295574fbaa82cc1592c18f64a","value":"Downloading: 100%"}},"ee986a976ff9463a8740e74c2b2e14f8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0a81ee35c2e646779fb0455b08fd98a4","max":579,"min":0,"orientation":"horizontal","style":"IPY_MODEL_298b9226ee9943a1aa45faaeb05794b3","value":579}},"a69e0c238e744573bc6774bc757852eb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d863541b48d94a1683b655fbff462a07","placeholder":"​","style":"IPY_MODEL_c1bf097c36e84fcf9328977835fc2466","value":" 579/579 [00:00&lt;00:00, 6.36kB/s]"}},"8263342e6f6e493faa3a843544b6417a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8dace4bebedf47328364eb53a24c6a90":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"78f9b26295574fbaa82cc1592c18f64a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0a81ee35c2e646779fb0455b08fd98a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"298b9226ee9943a1aa45faaeb05794b3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d863541b48d94a1683b655fbff462a07":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c1bf097c36e84fcf9328977835fc2466":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9af608790d214f48bc065f5899ff090b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_156edfa5455c440dae01697d1e7d29b5","IPY_MODEL_0bbeaaf310114ef4825c310cc9bca735","IPY_MODEL_9e689c2071b948d09cead8663a2d5d35"],"layout":"IPY_MODEL_70ef4b6a435b494898e925ade48e2893"}},"156edfa5455c440dae01697d1e7d29b5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6a8bb60cd1f043bca8866a21fbaa0e77","placeholder":"​","style":"IPY_MODEL_d7930503535d491995832f9528a1aea4","value":"Downloading: 100%"}},"0bbeaaf310114ef4825c310cc9bca735":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b6c4a6ee96fc4d359fe2ca23648d0aa1","max":2464616,"min":0,"orientation":"horizontal","style":"IPY_MODEL_521f2c8bea4e4acfb67129b865218eb3","value":2464616}},"9e689c2071b948d09cead8663a2d5d35":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ce859f5840df40c7a531461801852673","placeholder":"​","style":"IPY_MODEL_af0f5ba7d0c4446cae2f8a5e7e3f84d6","value":" 2.46M/2.46M [00:00&lt;00:00, 11.9MB/s]"}},"70ef4b6a435b494898e925ade48e2893":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a8bb60cd1f043bca8866a21fbaa0e77":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d7930503535d491995832f9528a1aea4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b6c4a6ee96fc4d359fe2ca23648d0aa1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"521f2c8bea4e4acfb67129b865218eb3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ce859f5840df40c7a531461801852673":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af0f5ba7d0c4446cae2f8a5e7e3f84d6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"gpuClass":"standard"},"cells":[{"cell_type":"code","source":["!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"71yb4mVrXrEt","executionInfo":{"status":"ok","timestamp":1666720303355,"user_tz":-540,"elapsed":11767,"user":{"displayName":"Bini Kim","userId":"16545463548428762859"}},"outputId":"6a0029d2-7eaa-4e27-e304-1953f6528218"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.23.1-py3-none-any.whl (5.3 MB)\n","\u001b[K     |████████████████████████████████| 5.3 MB 22.2 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n","Collecting huggingface-hub<1.0,>=0.10.0\n","  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n","\u001b[K     |████████████████████████████████| 163 kB 67.5 MB/s \n","\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 49.6 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.9.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.10.1 tokenizers-0.13.1 transformers-4.23.1\n"]}]},{"cell_type":"code","source":["pip install accelerate"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BeIlptjCRcEi","executionInfo":{"status":"ok","timestamp":1666720336865,"user_tz":-540,"elapsed":7716,"user":{"displayName":"Bini Kim","userId":"16545463548428762859"}},"outputId":"fec061b8-200d-4da6-e9e3-807332478adb"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting accelerate\n","  Downloading accelerate-0.13.2-py3-none-any.whl (148 kB)\n","\u001b[K     |████████████████████████████████| 148 kB 21.9 MB/s \n","\u001b[?25hRequirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from accelerate) (1.12.1+cu113)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from accelerate) (6.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from accelerate) (5.4.8)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from accelerate) (1.21.6)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from accelerate) (21.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->accelerate) (3.0.9)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4.0->accelerate) (4.1.1)\n","Installing collected packages: accelerate\n","Successfully installed accelerate-0.13.2\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from transformers import AutoModel\n","from transformers import AutoTokenizer\n","from sklearn.model_selection import train_test_split\n","import torch \n","import torch.nn as nn\n","from tqdm.notebook import tqdm\n","import matplotlib.pyplot as plt\n","from torch.utils.data import DataLoader, Dataset\n","from accelerate import Accelerator\n","import gc\n","\n","import os\n","os.environ[\"TOKENIZERS_PARALLELISM\"] = 'false'\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"metadata":{"id":"u9ICCyT30_l4","executionInfo":{"status":"ok","timestamp":1666720348363,"user_tz":-540,"elapsed":1766,"user":{"displayName":"Bini Kim","userId":"16545463548428762859"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["# Config"],"metadata":{"id":"LYCu8goJJTyw"}},{"cell_type":"code","source":["config = {\n","    'model' : \"microsoft/deberta-v3-base\",\n","    'dropout' : 0.,\n","    'max_length' : 512,\n","    'batch_size' : 32,\n","    'epochs' : 10,\n","    'lr' : 3e-4,\n","    'enable_scheduler' : True,\n","    'scheduler' : 'CosineAnnealingWarmRestarts',\n","    'gradient_accumulation_steps' : 2,\n","    'adam_eps' : 1e-6,\n","    'freeze_encoder' : True\n","}"],"metadata":{"id":"_5VDktIrJTFM","executionInfo":{"status":"ok","timestamp":1666720366860,"user_tz":-540,"elapsed":508,"user":{"displayName":"Bini Kim","userId":"16545463548428762859"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["# Tokenizer"],"metadata":{"id":"XzI42jbcJJgr"}},{"cell_type":"code","source":["pip install sentencepiece"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0f2Xy_LnGG4Q","executionInfo":{"status":"ok","timestamp":1666720380845,"user_tz":-540,"elapsed":5654,"user":{"displayName":"Bini Kim","userId":"16545463548428762859"}},"outputId":"24c74b60-3682-4c6e-d385-c6d5ad63a4be"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 25.0 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.97\n"]}]},{"cell_type":"code","source":["print(\"Loading Tokenizer...\")\n","tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-base\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":222,"referenced_widgets":["11d8b550829143a39c1fe70caf980c44","e8cf93285d0b41edb115c25d3fda89e0","05c72ab3efd24fe58d1e0d3380764d61","6037ed36a38a4782a368f2b07937dd51","c33ba02be0fa475b8956cf8df7cb78c0","4cc71a28f37c43669139610a0645fafe","78925eaa0b084505b742c0466c384adc","6f11fc47f21744409abeb48bbe594b10","a3afdcdb63a846bf9c0e1f1e9dbe7057","593016b8011c457cb21282cf54c37b91","2b5b1fee222649a39091e1eab028197e","91416c2f7bd84dadb58d9f5895931871","33c27f6e0bca4c1a8c134566b772e800","ee986a976ff9463a8740e74c2b2e14f8","a69e0c238e744573bc6774bc757852eb","8263342e6f6e493faa3a843544b6417a","8dace4bebedf47328364eb53a24c6a90","78f9b26295574fbaa82cc1592c18f64a","0a81ee35c2e646779fb0455b08fd98a4","298b9226ee9943a1aa45faaeb05794b3","d863541b48d94a1683b655fbff462a07","c1bf097c36e84fcf9328977835fc2466","9af608790d214f48bc065f5899ff090b","156edfa5455c440dae01697d1e7d29b5","0bbeaaf310114ef4825c310cc9bca735","9e689c2071b948d09cead8663a2d5d35","70ef4b6a435b494898e925ade48e2893","6a8bb60cd1f043bca8866a21fbaa0e77","d7930503535d491995832f9528a1aea4","b6c4a6ee96fc4d359fe2ca23648d0aa1","521f2c8bea4e4acfb67129b865218eb3","ce859f5840df40c7a531461801852673","af0f5ba7d0c4446cae2f8a5e7e3f84d6"]},"id":"Y6nzpSWYbcVT","executionInfo":{"status":"ok","timestamp":1666720409460,"user_tz":-540,"elapsed":12690,"user":{"displayName":"Bini Kim","userId":"16545463548428762859"}},"outputId":"cce33eac-ed2b-43cf-86fb-c0d3d54da69e"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading Tokenizer...\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11d8b550829143a39c1fe70caf980c44"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/579 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91416c2f7bd84dadb58d9f5895931871"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9af608790d214f48bc065f5899ff090b"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","/usr/local/lib/python3.7/dist-packages/transformers/convert_slow_tokenizer.py:447: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n","  \"The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option\"\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}]},{"cell_type":"code","source":["submission = pd.read_csv('/content/drive/MyDrive/ㄱ/sample_submission.csv')\n","train = pd.read_csv('/content/drive/MyDrive/ㄱ/train.csv')\n","test = pd.read_csv('/content/drive/MyDrive/ㄱ/test.csv')\n","print('Train DataFrame:', train.shape)\n","print('Train columns name:', train.columns.to_list())"],"metadata":{"id":"E03sJfvFYfby","executionInfo":{"status":"ok","timestamp":1666720500217,"user_tz":-540,"elapsed":740,"user":{"displayName":"Bini Kim","userId":"16545463548428762859"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"914893a2-c2e1-4aa9-b487-da403f15acf1"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Train DataFrame: (3911, 8)\n","Train columns name: ['text_id', 'full_text', 'cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n"]}]},{"cell_type":"code","source":["print('Number of trainig sentences: {:,}\\n'.format(train.shape[0]))\n","train.sample(10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":398},"id":"S9JQki4LbPtP","executionInfo":{"status":"ok","timestamp":1666720510560,"user_tz":-540,"elapsed":742,"user":{"displayName":"Bini Kim","userId":"16545463548428762859"}},"outputId":"31c446dd-603c-4421-9a14-548ba2330c8f"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of trainig sentences: 3,911\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["           text_id                                          full_text  \\\n","461   22D02123C65D  I agree with Churchill's statement about the r...   \n","3554  F131A67F5B95  Being yourself is better than try to be someon...   \n","269   136F4548CFD0  Some students think that summer break is good ...   \n","176   0D65AF80CDE7  It has been said that first impressions are al...   \n","860   420269F2DE40  Teenagers are really complicated these day's n...   \n","1995  9715AAF5B952  Have you thought about your first impression o...   \n","864   424005E31A04  Do people ever told that having a positive att...   \n","2919  D28F4250040D  Imagine running through the wind so fast with ...   \n","331   185E2F7317F2  A problem is something that can make a differe...   \n","2210  A4CD4307D620  Part of growing in this life is having the rig...   \n","\n","      cohesion  syntax  vocabulary  phraseology  grammar  conventions  \n","461        3.0     3.0         3.0          3.5      3.0          3.0  \n","3554       3.5     3.0         3.5          3.0      2.5          3.0  \n","269        2.5     2.0         2.5          2.5      2.5          2.5  \n","176        2.0     2.5         2.0          2.0      2.5          2.5  \n","860        2.5     3.0         3.0          3.0      2.0          2.5  \n","1995       3.5     3.5         3.0          3.5      3.0          3.5  \n","864        3.0     4.0         4.0          3.0      3.0          3.0  \n","2919       3.5     2.5         3.5          3.0      3.0          2.5  \n","331        3.5     3.5         4.0          4.0      3.5          3.5  \n","2210       3.0     3.0         3.0          3.5      3.5          3.0  "],"text/html":["\n","  <div id=\"df-f0550d2f-8bc3-4119-b5a3-da2d0ae599ad\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text_id</th>\n","      <th>full_text</th>\n","      <th>cohesion</th>\n","      <th>syntax</th>\n","      <th>vocabulary</th>\n","      <th>phraseology</th>\n","      <th>grammar</th>\n","      <th>conventions</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>461</th>\n","      <td>22D02123C65D</td>\n","      <td>I agree with Churchill's statement about the r...</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.5</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>3554</th>\n","      <td>F131A67F5B95</td>\n","      <td>Being yourself is better than try to be someon...</td>\n","      <td>3.5</td>\n","      <td>3.0</td>\n","      <td>3.5</td>\n","      <td>3.0</td>\n","      <td>2.5</td>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>269</th>\n","      <td>136F4548CFD0</td>\n","      <td>Some students think that summer break is good ...</td>\n","      <td>2.5</td>\n","      <td>2.0</td>\n","      <td>2.5</td>\n","      <td>2.5</td>\n","      <td>2.5</td>\n","      <td>2.5</td>\n","    </tr>\n","    <tr>\n","      <th>176</th>\n","      <td>0D65AF80CDE7</td>\n","      <td>It has been said that first impressions are al...</td>\n","      <td>2.0</td>\n","      <td>2.5</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>2.5</td>\n","      <td>2.5</td>\n","    </tr>\n","    <tr>\n","      <th>860</th>\n","      <td>420269F2DE40</td>\n","      <td>Teenagers are really complicated these day's n...</td>\n","      <td>2.5</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>2.0</td>\n","      <td>2.5</td>\n","    </tr>\n","    <tr>\n","      <th>1995</th>\n","      <td>9715AAF5B952</td>\n","      <td>Have you thought about your first impression o...</td>\n","      <td>3.5</td>\n","      <td>3.5</td>\n","      <td>3.0</td>\n","      <td>3.5</td>\n","      <td>3.0</td>\n","      <td>3.5</td>\n","    </tr>\n","    <tr>\n","      <th>864</th>\n","      <td>424005E31A04</td>\n","      <td>Do people ever told that having a positive att...</td>\n","      <td>3.0</td>\n","      <td>4.0</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>2919</th>\n","      <td>D28F4250040D</td>\n","      <td>Imagine running through the wind so fast with ...</td>\n","      <td>3.5</td>\n","      <td>2.5</td>\n","      <td>3.5</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>2.5</td>\n","    </tr>\n","    <tr>\n","      <th>331</th>\n","      <td>185E2F7317F2</td>\n","      <td>A problem is something that can make a differe...</td>\n","      <td>3.5</td>\n","      <td>3.5</td>\n","      <td>4.0</td>\n","      <td>4.0</td>\n","      <td>3.5</td>\n","      <td>3.5</td>\n","    </tr>\n","    <tr>\n","      <th>2210</th>\n","      <td>A4CD4307D620</td>\n","      <td>Part of growing in this life is having the rig...</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.5</td>\n","      <td>3.5</td>\n","      <td>3.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f0550d2f-8bc3-4119-b5a3-da2d0ae599ad')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f0550d2f-8bc3-4119-b5a3-da2d0ae599ad button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f0550d2f-8bc3-4119-b5a3-da2d0ae599ad');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["# Get the lists of sentences and their labels.\n","full_text = train.full_text.values\n","labels = train.grammar.values"],"metadata":{"id":"MmqEhKtVbapi","executionInfo":{"status":"ok","timestamp":1666720527761,"user_tz":-540,"elapsed":498,"user":{"displayName":"Bini Kim","userId":"16545463548428762859"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# 오리지널 문장\n","print('Original : ', full_text[0])\n","# 토큰으로 분할 된 문장\n","print('Tokenized : ',tokenizer.tokenize(full_text[0]))\n","# token ids에 매핑된 문장\n","# input_ids는 문장의 각 토큰에 해당하는 인덱스입니다.\n","print('Token IDs : ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(full_text[0])))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9T7poDErbd3K","executionInfo":{"status":"ok","timestamp":1666720530503,"user_tz":-540,"elapsed":2,"user":{"displayName":"Bini Kim","userId":"16545463548428762859"}},"outputId":"12741be4-d6ae-4f7a-8002-176b36f88b06"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Original :  I think that students would benefit from learning at home,because they wont have to change and get up early in the morning to shower and do there hair. taking only classes helps them because at there house they'll be pay more attention. they will be comfortable at home.\n","\n","The hardest part of school is getting ready. you wake up go brush your teeth and go to your closet and look at your cloths. after you think you picked a outfit u go look in the mirror and youll either not like it or you look and see a stain. Then you'll have to change. with the online classes you can wear anything and stay home and you wont need to stress about what to wear.\n","\n","most students usually take showers before school. they either take it before they sleep or when they wake up. some students do both to smell good. that causes them do miss the bus and effects on there lesson time cause they come late to school. when u have online classes u wont need to miss lessons cause you can get everything set up and go take a shower and when u get out your ready to go.\n","\n","when your home your comfortable and you pay attention. it gives then an advantage to be smarter and even pass there classmates on class work. public schools are difficult even if you try. some teacher dont know how to teach it in then way that students understand it. that causes students to fail and they may repeat the class.              \n","Tokenized :  ['▁I', '▁think', '▁that', '▁students', '▁would', '▁benefit', '▁from', '▁learning', '▁at', '▁home', ',', 'because', '▁they', '▁wont', '▁have', '▁to', '▁change', '▁and', '▁get', '▁up', '▁early', '▁in', '▁the', '▁morning', '▁to', '▁shower', '▁and', '▁do', '▁there', '▁hair', '.', '▁taking', '▁only', '▁classes', '▁helps', '▁them', '▁because', '▁at', '▁there', '▁house', '▁they', \"'\", 'll', '▁be', '▁pay', '▁more', '▁attention', '.', '▁they', '▁will', '▁be', '▁comfortable', '▁at', '▁home', '.', '▁The', '▁hardest', '▁part', '▁of', '▁school', '▁is', '▁getting', '▁ready', '.', '▁you', '▁wake', '▁up', '▁go', '▁brush', '▁your', '▁teeth', '▁and', '▁go', '▁to', '▁your', '▁closet', '▁and', '▁look', '▁at', '▁your', '▁cloths', '.', '▁after', '▁you', '▁think', '▁you', '▁picked', '▁a', '▁outfit', '▁u', '▁go', '▁look', '▁in', '▁the', '▁mirror', '▁and', '▁you', 'll', '▁either', '▁not', '▁like', '▁it', '▁or', '▁you', '▁look', '▁and', '▁see', '▁a', '▁stain', '.', '▁Then', '▁you', \"'\", 'll', '▁have', '▁to', '▁change', '.', '▁with', '▁the', '▁online', '▁classes', '▁you', '▁can', '▁wear', '▁anything', '▁and', '▁stay', '▁home', '▁and', '▁you', '▁wont', '▁need', '▁to', '▁stress', '▁about', '▁what', '▁to', '▁wear', '.', '▁most', '▁students', '▁usually', '▁take', '▁showers', '▁before', '▁school', '.', '▁they', '▁either', '▁take', '▁it', '▁before', '▁they', '▁sleep', '▁or', '▁when', '▁they', '▁wake', '▁up', '.', '▁some', '▁students', '▁do', '▁both', '▁to', '▁smell', '▁good', '.', '▁that', '▁causes', '▁them', '▁do', '▁miss', '▁the', '▁bus', '▁and', '▁effects', '▁on', '▁there', '▁lesson', '▁time', '▁cause', '▁they', '▁come', '▁late', '▁to', '▁school', '.', '▁when', '▁u', '▁have', '▁online', '▁classes', '▁u', '▁wont', '▁need', '▁to', '▁miss', '▁lessons', '▁cause', '▁you', '▁can', '▁get', '▁everything', '▁set', '▁up', '▁and', '▁go', '▁take', '▁a', '▁shower', '▁and', '▁when', '▁u', '▁get', '▁out', '▁your', '▁ready', '▁to', '▁go', '.', '▁when', '▁your', '▁home', '▁your', '▁comfortable', '▁and', '▁you', '▁pay', '▁attention', '.', '▁it', '▁gives', '▁then', '▁an', '▁advantage', '▁to', '▁be', '▁smarter', '▁and', '▁even', '▁pass', '▁there', '▁classmates', '▁on', '▁class', '▁work', '.', '▁public', '▁schools', '▁are', '▁difficult', '▁even', '▁if', '▁you', '▁try', '.', '▁some', '▁teacher', '▁dont', '▁know', '▁how', '▁to', '▁teach', '▁it', '▁in', '▁then', '▁way', '▁that', '▁students', '▁understand', '▁it', '.', '▁that', '▁causes', '▁students', '▁to', '▁fail', '▁and', '▁they', '▁may', '▁repeat', '▁the', '▁class', '.']\n","Token IDs :  [273, 428, 272, 598, 338, 1591, 292, 1101, 288, 425, 261, 10405, 306, 13521, 286, 264, 575, 263, 350, 322, 737, 267, 262, 1066, 264, 3038, 263, 333, 343, 1245, 260, 787, 364, 2141, 1530, 349, 401, 288, 343, 669, 306, 280, 436, 282, 794, 310, 1251, 260, 306, 296, 282, 1800, 288, 425, 260, 279, 9769, 465, 265, 563, 269, 646, 1041, 260, 274, 4302, 322, 424, 5063, 290, 3261, 263, 424, 264, 290, 6928, 263, 468, 288, 290, 36738, 260, 385, 274, 428, 274, 2847, 266, 5776, 3636, 424, 468, 267, 262, 4520, 263, 274, 436, 814, 298, 334, 278, 289, 274, 468, 263, 398, 266, 10997, 260, 1060, 274, 280, 436, 286, 264, 575, 260, 275, 262, 535, 2141, 274, 295, 1929, 784, 263, 992, 425, 263, 274, 13521, 389, 264, 2148, 314, 339, 264, 1929, 260, 370, 598, 1048, 413, 10796, 416, 563, 260, 306, 814, 413, 278, 416, 306, 1873, 289, 335, 306, 4302, 322, 260, 347, 598, 333, 462, 264, 4984, 397, 260, 272, 2884, 349, 333, 2374, 262, 2444, 263, 1563, 277, 343, 4178, 326, 1138, 306, 488, 1109, 264, 563, 260, 335, 3636, 286, 535, 2141, 3636, 13521, 389, 264, 2374, 3620, 1138, 274, 295, 350, 758, 487, 322, 263, 424, 413, 266, 3038, 263, 335, 3636, 350, 321, 290, 1041, 264, 424, 260, 335, 290, 425, 290, 1800, 263, 274, 794, 1251, 260, 278, 1360, 393, 299, 1951, 264, 282, 13245, 263, 402, 1633, 343, 16133, 277, 938, 374, 260, 613, 1657, 281, 1179, 402, 337, 274, 687, 260, 347, 2274, 6421, 391, 361, 264, 2900, 278, 267, 393, 384, 272, 598, 796, 278, 260, 272, 2884, 598, 264, 3703, 263, 306, 372, 5204, 262, 938, 260]\n"]}]},{"cell_type":"markdown","source":["# Dataset"],"metadata":{"id":"xEVlpgMnSYIQ"}},{"cell_type":"code","source":["input_ids = []\n","attention_masks = []\n","\n","for text in full_text:\n","    encoded_dict = tokenizer.encode_plus(\n","                    text,\n","                    add_special_tokens = True,\n","                    max_length = 512, \n","                    truncation=True,\n","                    pad_to_max_length = True,\n","                    return_attention_mask = True,\n","                    return_tensors = 'pt' \n","                    )\n","    \n","    input_ids.append(encoded_dict['input_ids'])\n","    \n","    attention_masks.append(encoded_dict['attention_mask'])\n","    \n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","labels = torch.tensor(labels)\n","\n","print('Original: ', full_text[0])\n","print('Token IDs: ', input_ids[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wR5IR719bf2v","executionInfo":{"status":"ok","timestamp":1666720749652,"user_tz":-540,"elapsed":10255,"user":{"displayName":"Bini Kim","userId":"16545463548428762859"}},"outputId":"61dc60e2-a8d3-407e-860a-54e7f62ab2e2"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2308: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]},{"output_type":"stream","name":"stdout","text":["Original:  I think that students would benefit from learning at home,because they wont have to change and get up early in the morning to shower and do there hair. taking only classes helps them because at there house they'll be pay more attention. they will be comfortable at home.\n","\n","The hardest part of school is getting ready. you wake up go brush your teeth and go to your closet and look at your cloths. after you think you picked a outfit u go look in the mirror and youll either not like it or you look and see a stain. Then you'll have to change. with the online classes you can wear anything and stay home and you wont need to stress about what to wear.\n","\n","most students usually take showers before school. they either take it before they sleep or when they wake up. some students do both to smell good. that causes them do miss the bus and effects on there lesson time cause they come late to school. when u have online classes u wont need to miss lessons cause you can get everything set up and go take a shower and when u get out your ready to go.\n","\n","when your home your comfortable and you pay attention. it gives then an advantage to be smarter and even pass there classmates on class work. public schools are difficult even if you try. some teacher dont know how to teach it in then way that students understand it. that causes students to fail and they may repeat the class.              \n","Token IDs:  tensor([    1,   273,   428,   272,   598,   338,  1591,   292,  1101,   288,\n","          425,   261, 10405,   306, 13521,   286,   264,   575,   263,   350,\n","          322,   737,   267,   262,  1066,   264,  3038,   263,   333,   343,\n","         1245,   260,   787,   364,  2141,  1530,   349,   401,   288,   343,\n","          669,   306,   280,   436,   282,   794,   310,  1251,   260,   306,\n","          296,   282,  1800,   288,   425,   260,   279,  9769,   465,   265,\n","          563,   269,   646,  1041,   260,   274,  4302,   322,   424,  5063,\n","          290,  3261,   263,   424,   264,   290,  6928,   263,   468,   288,\n","          290, 36738,   260,   385,   274,   428,   274,  2847,   266,  5776,\n","         3636,   424,   468,   267,   262,  4520,   263,   274,   436,   814,\n","          298,   334,   278,   289,   274,   468,   263,   398,   266, 10997,\n","          260,  1060,   274,   280,   436,   286,   264,   575,   260,   275,\n","          262,   535,  2141,   274,   295,  1929,   784,   263,   992,   425,\n","          263,   274, 13521,   389,   264,  2148,   314,   339,   264,  1929,\n","          260,   370,   598,  1048,   413, 10796,   416,   563,   260,   306,\n","          814,   413,   278,   416,   306,  1873,   289,   335,   306,  4302,\n","          322,   260,   347,   598,   333,   462,   264,  4984,   397,   260,\n","          272,  2884,   349,   333,  2374,   262,  2444,   263,  1563,   277,\n","          343,  4178,   326,  1138,   306,   488,  1109,   264,   563,   260,\n","          335,  3636,   286,   535,  2141,  3636, 13521,   389,   264,  2374,\n","         3620,  1138,   274,   295,   350,   758,   487,   322,   263,   424,\n","          413,   266,  3038,   263,   335,  3636,   350,   321,   290,  1041,\n","          264,   424,   260,   335,   290,   425,   290,  1800,   263,   274,\n","          794,  1251,   260,   278,  1360,   393,   299,  1951,   264,   282,\n","        13245,   263,   402,  1633,   343, 16133,   277,   938,   374,   260,\n","          613,  1657,   281,  1179,   402,   337,   274,   687,   260,   347,\n","         2274,  6421,   391,   361,   264,  2900,   278,   267,   393,   384,\n","          272,   598,   796,   278,   260,   272,  2884,   598,   264,  3703,\n","          263,   306,   372,  5204,   262,   938,   260,     2,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0])\n"]}]},{"cell_type":"markdown","source":["# train_valid_split"],"metadata":{"id":"iC_PeWk_TOoR"}},{"cell_type":"code","source":["from torch.utils.data import TensorDataset, random_split\n","# training inputs을 TensorDataset에 결합\n","dataset = TensorDataset(input_ids, attention_masks, labels)\n","\n","#90-10 train-validation split.\n","#각 세트에 포함할 샘플 수를 계산\n","train_size = int(0.9 * len(dataset))\n","val_size = len(dataset) - train_size\n","\n","#무작위로 샘플을 선택하여 데이터 세트를 나눈다.\n","train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n","\n","print('{:>5,} training samples'.format(train_size))\n","print('{:>5,} validation samples'.format(val_size))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8kF6OAyJbnRD","executionInfo":{"status":"ok","timestamp":1666721365252,"user_tz":-540,"elapsed":474,"user":{"displayName":"Bini Kim","userId":"16545463548428762859"}},"outputId":"39580c14-a28b-4742-ecde-4dfc234a99f4"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["3,519 training samples\n","  392 validation samples\n"]}]},{"cell_type":"markdown","source":["# DataLoader"],"metadata":{"id":"ToKWPi1ETh08"}},{"cell_type":"code","source":["from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","\n","batch_size = 32\n","\n","train_dataloader = DataLoader(\n","            train_dataset, \n","            batch_size = batch_size,\n","            shuffle = True,\n","            num_workers = 2,\n","            pin_memory=True\n","        )\n","\n","\n","valid_dataloader = DataLoader(\n","            val_dataset, \n","            batch_size = batch_size,\n","            shuffle = True,\n","            num_workers = 2,\n","            pin_memory=True\n","        )"],"metadata":{"id":"ZFhk__zlbt9l","executionInfo":{"status":"ok","timestamp":1666721366467,"user_tz":-540,"elapsed":1,"user":{"displayName":"Bini Kim","userId":"16545463548428762859"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["print('loader shapes:',len(train_dataloader), len(valid_dataloader))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-xJHG1VOKwae","executionInfo":{"status":"ok","timestamp":1666721367641,"user_tz":-540,"elapsed":2,"user":{"displayName":"Bini Kim","userId":"16545463548428762859"}},"outputId":"8c4727a1-67f6-4a9e-d712-4ccb91a35ed3"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["loader shapes: 110 13\n"]}]},{"cell_type":"markdown","source":["# MeanPooling"],"metadata":{"id":"txbDm1ROVkHQ"}},{"cell_type":"code","source":["class MeanPooling(nn.Module):\n","    def __init__(self):\n","        super(MeanPooling, self).__init__()\n","        \n","    def forward(self, last_hidden_state, attention_mask):\n","        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n","        sum_mask = input_mask_expanded.sum(1)\n","        sum_mask = torch.clamp(sum_mask, min=1e-9)\n","        mean_embeddings = sum_embeddings / sum_mask\n","        return mean_embeddings"],"metadata":{"id":"LS8PByewVgwJ","executionInfo":{"status":"ok","timestamp":1666721411347,"user_tz":-540,"elapsed":513,"user":{"displayName":"Bini Kim","userId":"16545463548428762859"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["from transformers import AutoModel, AdamW, BertConfig\n","\n","model = AutoModel.from_pretrained(\n","        \"microsoft/deberta-v3-base\", # 12레이어 버트 모델 사용 (uncased)\n","        num_labels = 1, #출력 레이블 수 (2진 분류의 경우 2)\n","        output_attentions = False, #모델이 attention 가중치를 리턴하는지\n","        output_hidden_states = False, #모델이 hidden states를 리턴하는지\n","        #attention_probs_dropout_prob=0.4,\n","        #hidden_dropout_prob=0.4,\n",")\n","# GPU에서 이 모델을 실행하도록 pytorch에 지시\n","model.cuda()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"058_YBrVbwf2","executionInfo":{"status":"ok","timestamp":1666721484748,"user_tz":-540,"elapsed":4168,"user":{"displayName":"Bini Kim","userId":"16545463548428762859"}},"outputId":"30ef9a5a-cb50-4ec6-923b-c114534a3e7c"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.bias', 'mask_predictions.classifier.weight', 'mask_predictions.dense.weight']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"execute_result","data":{"text/plain":["DebertaV2Model(\n","  (embeddings): DebertaV2Embeddings(\n","    (word_embeddings): Embedding(128100, 768, padding_idx=0)\n","    (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","    (dropout): StableDropout()\n","  )\n","  (encoder): DebertaV2Encoder(\n","    (layer): ModuleList(\n","      (0): DebertaV2Layer(\n","        (attention): DebertaV2Attention(\n","          (self): DisentangledSelfAttention(\n","            (query_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (key_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (value_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (pos_dropout): StableDropout()\n","            (dropout): StableDropout()\n","          )\n","          (output): DebertaV2SelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","            (dropout): StableDropout()\n","          )\n","        )\n","        (intermediate): DebertaV2Intermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          (intermediate_act_fn): GELUActivation()\n","        )\n","        (output): DebertaV2Output(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","          (dropout): StableDropout()\n","        )\n","      )\n","      (1): DebertaV2Layer(\n","        (attention): DebertaV2Attention(\n","          (self): DisentangledSelfAttention(\n","            (query_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (key_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (value_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (pos_dropout): StableDropout()\n","            (dropout): StableDropout()\n","          )\n","          (output): DebertaV2SelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","            (dropout): StableDropout()\n","          )\n","        )\n","        (intermediate): DebertaV2Intermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          (intermediate_act_fn): GELUActivation()\n","        )\n","        (output): DebertaV2Output(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","          (dropout): StableDropout()\n","        )\n","      )\n","      (2): DebertaV2Layer(\n","        (attention): DebertaV2Attention(\n","          (self): DisentangledSelfAttention(\n","            (query_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (key_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (value_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (pos_dropout): StableDropout()\n","            (dropout): StableDropout()\n","          )\n","          (output): DebertaV2SelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","            (dropout): StableDropout()\n","          )\n","        )\n","        (intermediate): DebertaV2Intermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          (intermediate_act_fn): GELUActivation()\n","        )\n","        (output): DebertaV2Output(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","          (dropout): StableDropout()\n","        )\n","      )\n","      (3): DebertaV2Layer(\n","        (attention): DebertaV2Attention(\n","          (self): DisentangledSelfAttention(\n","            (query_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (key_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (value_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (pos_dropout): StableDropout()\n","            (dropout): StableDropout()\n","          )\n","          (output): DebertaV2SelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","            (dropout): StableDropout()\n","          )\n","        )\n","        (intermediate): DebertaV2Intermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          (intermediate_act_fn): GELUActivation()\n","        )\n","        (output): DebertaV2Output(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","          (dropout): StableDropout()\n","        )\n","      )\n","      (4): DebertaV2Layer(\n","        (attention): DebertaV2Attention(\n","          (self): DisentangledSelfAttention(\n","            (query_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (key_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (value_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (pos_dropout): StableDropout()\n","            (dropout): StableDropout()\n","          )\n","          (output): DebertaV2SelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","            (dropout): StableDropout()\n","          )\n","        )\n","        (intermediate): DebertaV2Intermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          (intermediate_act_fn): GELUActivation()\n","        )\n","        (output): DebertaV2Output(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","          (dropout): StableDropout()\n","        )\n","      )\n","      (5): DebertaV2Layer(\n","        (attention): DebertaV2Attention(\n","          (self): DisentangledSelfAttention(\n","            (query_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (key_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (value_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (pos_dropout): StableDropout()\n","            (dropout): StableDropout()\n","          )\n","          (output): DebertaV2SelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","            (dropout): StableDropout()\n","          )\n","        )\n","        (intermediate): DebertaV2Intermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          (intermediate_act_fn): GELUActivation()\n","        )\n","        (output): DebertaV2Output(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","          (dropout): StableDropout()\n","        )\n","      )\n","      (6): DebertaV2Layer(\n","        (attention): DebertaV2Attention(\n","          (self): DisentangledSelfAttention(\n","            (query_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (key_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (value_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (pos_dropout): StableDropout()\n","            (dropout): StableDropout()\n","          )\n","          (output): DebertaV2SelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","            (dropout): StableDropout()\n","          )\n","        )\n","        (intermediate): DebertaV2Intermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          (intermediate_act_fn): GELUActivation()\n","        )\n","        (output): DebertaV2Output(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","          (dropout): StableDropout()\n","        )\n","      )\n","      (7): DebertaV2Layer(\n","        (attention): DebertaV2Attention(\n","          (self): DisentangledSelfAttention(\n","            (query_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (key_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (value_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (pos_dropout): StableDropout()\n","            (dropout): StableDropout()\n","          )\n","          (output): DebertaV2SelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","            (dropout): StableDropout()\n","          )\n","        )\n","        (intermediate): DebertaV2Intermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          (intermediate_act_fn): GELUActivation()\n","        )\n","        (output): DebertaV2Output(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","          (dropout): StableDropout()\n","        )\n","      )\n","      (8): DebertaV2Layer(\n","        (attention): DebertaV2Attention(\n","          (self): DisentangledSelfAttention(\n","            (query_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (key_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (value_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (pos_dropout): StableDropout()\n","            (dropout): StableDropout()\n","          )\n","          (output): DebertaV2SelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","            (dropout): StableDropout()\n","          )\n","        )\n","        (intermediate): DebertaV2Intermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          (intermediate_act_fn): GELUActivation()\n","        )\n","        (output): DebertaV2Output(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","          (dropout): StableDropout()\n","        )\n","      )\n","      (9): DebertaV2Layer(\n","        (attention): DebertaV2Attention(\n","          (self): DisentangledSelfAttention(\n","            (query_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (key_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (value_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (pos_dropout): StableDropout()\n","            (dropout): StableDropout()\n","          )\n","          (output): DebertaV2SelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","            (dropout): StableDropout()\n","          )\n","        )\n","        (intermediate): DebertaV2Intermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          (intermediate_act_fn): GELUActivation()\n","        )\n","        (output): DebertaV2Output(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","          (dropout): StableDropout()\n","        )\n","      )\n","      (10): DebertaV2Layer(\n","        (attention): DebertaV2Attention(\n","          (self): DisentangledSelfAttention(\n","            (query_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (key_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (value_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (pos_dropout): StableDropout()\n","            (dropout): StableDropout()\n","          )\n","          (output): DebertaV2SelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","            (dropout): StableDropout()\n","          )\n","        )\n","        (intermediate): DebertaV2Intermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          (intermediate_act_fn): GELUActivation()\n","        )\n","        (output): DebertaV2Output(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","          (dropout): StableDropout()\n","        )\n","      )\n","      (11): DebertaV2Layer(\n","        (attention): DebertaV2Attention(\n","          (self): DisentangledSelfAttention(\n","            (query_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (key_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (value_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (pos_dropout): StableDropout()\n","            (dropout): StableDropout()\n","          )\n","          (output): DebertaV2SelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","            (dropout): StableDropout()\n","          )\n","        )\n","        (intermediate): DebertaV2Intermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          (intermediate_act_fn): GELUActivation()\n","        )\n","        (output): DebertaV2Output(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","          (dropout): StableDropout()\n","        )\n","      )\n","    )\n","    (rel_embeddings): Embedding(512, 768)\n","    (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","  )\n",")"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["# 모델의 모든 parameters를 튜플 목록으로 가져옴.\n","params = list(model.named_parameters())\n","\n","print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n","\n","print('==== Embedding Layer ====\\n')\n","\n","for p in params[0:5]:\n","    print(\"{:<55}{:12}\".format(p[0], str(tuple(p[1].size()))))\n","    \n","print('\\n==== First Transformer ====\\n')\n","\n","for p in params[5:21]:\n","    print(\"{:55}{:12}\".format(p[0], str(tuple(p[1].size()))))\n","    \n","print('\\n==== Output Layer ====\\n')\n","\n","for p in params[-4:]:\n","    print(\"{:55}{:12}\".format(p[0], str(tuple(p[1].size()))))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-mXzZ3GxbyU0","executionInfo":{"status":"ok","timestamp":1666721499443,"user_tz":-540,"elapsed":543,"user":{"displayName":"Bini Kim","userId":"16545463548428762859"}},"outputId":"f002b793-282b-4664-a1ec-b4b4be94fa88"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["The BERT model has 198 different named parameters.\n","\n","==== Embedding Layer ====\n","\n","embeddings.word_embeddings.weight                      (128100, 768)\n","embeddings.LayerNorm.weight                            (768,)      \n","embeddings.LayerNorm.bias                              (768,)      \n","encoder.layer.0.attention.self.query_proj.weight       (768, 768)  \n","encoder.layer.0.attention.self.query_proj.bias         (768,)      \n","\n","==== First Transformer ====\n","\n","encoder.layer.0.attention.self.key_proj.weight         (768, 768)  \n","encoder.layer.0.attention.self.key_proj.bias           (768,)      \n","encoder.layer.0.attention.self.value_proj.weight       (768, 768)  \n","encoder.layer.0.attention.self.value_proj.bias         (768,)      \n","encoder.layer.0.attention.output.dense.weight          (768, 768)  \n","encoder.layer.0.attention.output.dense.bias            (768,)      \n","encoder.layer.0.attention.output.LayerNorm.weight      (768,)      \n","encoder.layer.0.attention.output.LayerNorm.bias        (768,)      \n","encoder.layer.0.intermediate.dense.weight              (3072, 768) \n","encoder.layer.0.intermediate.dense.bias                (3072,)     \n","encoder.layer.0.output.dense.weight                    (768, 3072) \n","encoder.layer.0.output.dense.bias                      (768,)      \n","encoder.layer.0.output.LayerNorm.weight                (768,)      \n","encoder.layer.0.output.LayerNorm.bias                  (768,)      \n","encoder.layer.1.attention.self.query_proj.weight       (768, 768)  \n","encoder.layer.1.attention.self.query_proj.bias         (768,)      \n","\n","==== Output Layer ====\n","\n","encoder.layer.11.output.LayerNorm.bias                 (768,)      \n","encoder.rel_embeddings.weight                          (512, 768)  \n","encoder.LayerNorm.weight                               (768,)      \n","encoder.LayerNorm.bias                                 (768,)      \n"]}]},{"cell_type":"code","source":["optimizer = AdamW(model.parameters(),\n","                 lr = 2e-5, #arg.learning_rate - 기본값은 5e-5이고 노트북에는 2e-5가 있다.\n","                 eps = 1e-8) #arg.adam_epsilon - 기본값은 1e-8"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xEiP5eBcb5OQ","executionInfo":{"status":"ok","timestamp":1666721499955,"user_tz":-540,"elapsed":3,"user":{"displayName":"Bini Kim","userId":"16545463548428762859"}},"outputId":"a0318352-a07d-4cf5-9ef6-fc00d91b0c69"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n"]}]},{"cell_type":"code","source":["from transformers import get_linear_schedule_with_warmup\n","\n","# Number of training epochs. 2-4사이 권장\n","# 4를 선택하지만 과적합될수있음\n","epochs = 10\n","# 총 훈련 단계 수는 [배치 수] X [에포크 수]\n","# (훈련 샘플의 수와 동일하지 않음)\n","total_steps = len(train_dataloader) * epochs\n","\n","# learning rate scheduler 만들기\n","scheduler = get_linear_schedule_with_warmup(optimizer,\n","                                           num_warmup_steps = 0,\n","                                           num_training_steps = total_steps)"],"metadata":{"id":"PIQv2fprb_VJ","executionInfo":{"status":"ok","timestamp":1666721503406,"user_tz":-540,"elapsed":2,"user":{"displayName":"Bini Kim","userId":"16545463548428762859"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","# 예측 vs 레이블의 정확도를 계산하는 함수\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"],"metadata":{"id":"0eR3c7b1cAmX","executionInfo":{"status":"ok","timestamp":1666721505715,"user_tz":-540,"elapsed":1,"user":{"displayName":"Bini Kim","userId":"16545463548428762859"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["import time\n","import datetime\n","\n","def format_time(elapsed):\n","    #가까운 초로 반올림\n","    elapsed_rounded = int(round((elapsed)))\n","    #format as hh:mm:ss\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"],"metadata":{"id":"mYHh4Vo8cCgA","executionInfo":{"status":"ok","timestamp":1666721512165,"user_tz":-540,"elapsed":2,"user":{"displayName":"Bini Kim","userId":"16545463548428762859"}}},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":["# Train"],"metadata":{"id":"_8Ow62aJWBqp"}},{"cell_type":"code","source":["import random\n","import numpy as np\n","\n","#모든 곳에 seed 값을 설정하기\n","seed_val = 42\n","\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","training_stats = []\n","total_t0 = time.time()\n","\n","for epoch_i in range(0, epochs):\n","    print(\"\")\n","    print('=======Epoch {:} / {:} ======='.format(epoch_i+1, epochs))\n","    print(\"Training...\")\n","    \n","    t0 =time.time()\n","    total_train_loss = 0\n","    model.train()\n","    \n","    for step, batch in enumerate(train_dataloader):\n","        if step % 40 == 0 and not step == 0:\n","            elapsed = format_time(time.time()-t0)\n","            print(' Batch {:>5,} of {:>5,}. Elapsed: {:}'.format(step, len(train_dataloader), elapsed))\n","    \n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device, dtype=torch.float32)\n","\n","\n","        model.zero_grad()\n","    \n","        loss, logits = model(b_input_ids,\n","                            token_type_ids=None,\n","                            attention_mask=b_input_mask,\n","                            labels = b_labels,)\n","    \n","        total_train_loss += loss.item()\n","\n","        loss.backward()\n","\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        optimizer.step()\n","\n","\n","        scheduler.step()\n","    \n","    avg_train_loss = total_train_loss / len(train_dataloader)\n","\n","    training_time = format_time(time.time() - t0)\n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epoch took: {:}\".format(training_time))\n","    \n","    # ======validation======\n","    #각 training epoch를 완료 후 성능을 측정함\n","    # VALIDATION SET\n","    \n","    print(\"\")\n","    print(\"Running Validation...\")\n","    \n","    t0 = time.time()\n","    \n","    # 모델을 평가 모드에. dropout layer가 다르게 작동함\n","    model.eval()\n","    \n","    #Tracking variables\n","    total_eval_accuracy = 0\n","    total_eval_loss = 0\n","    nb_eval_steps = 0\n","    \n","    #Evaluate data for one epoch\n","    for batch in valid_dataloader:\n","        #DataLoader에서 training batch 압축 해제\n","        #batch의 압축을 풀면서 각 텐서를 GPU에 복사\n","        #\"to\"method.\n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device, dtype=torch.float32)\n","        \n","        #pytorch에게 compute 그래프를 구성하는동안 귀찮게 하지 말라고 하기\n","        #forward pass ; backprop (역전파) training에만 필요\n","        with torch.no_grad():\n","            \n","            #forward pass : logit predictions를 계산\n","            #token_type_ids는 \"segment ids\"와 동일\n","            # 2문장 작업에서 문장 1과 2를 구별\n","            \n","            #모델의 logits의 출력을 가져옴. \n","            #softmax 함수를 적용하기 전 값\n","            (loss, logits) = model(b_input_ids,\n","                                  token_type_ids=None,\n","                                  attention_mask=b_input_mask,\n","                                  labels=b_labels,\n","                                  return_dict=False)\n","        #validation loss를 누적\n","        total_eval_loss += loss.item()\n","        \n","        #logits, labels 는 CPU로 이동\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","        \n","        # test 문장 batch 정확도를 계산하고 모든 batch에 누적함\n","        total_eval_accuracy += flat_accuracy(logits, label_ids)\n","        \n","    # validation 실행에 대한 최종 정확도를 보고함.\n","    avg_val_accuracy = total_eval_accuracy / len(valid_dataloader)\n","    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n","    \n","    #모든 배치에 대한 평균 loss를 계산\n","    avg_val_loss = total_eval_loss / len(valid_dataloader)\n","    \n","    #validation실행에 걸린 시간을 측정\n","    validation_time = format_time(time.time()-t0)\n","    \n","    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n","    print(\"  Validation took: {:}\".format(validation_time))\n","    \n","    # epoch의 모든 통계를 기록\n","    training_stats.append(\n","        {\n","            'epoch': epoch_i+1,\n","            'Training Loss' : avg_train_loss,\n","            'Valid. Loss' : avg_val_loss,\n","            'Valid. Accur.' : avg_val_accuracy,\n","            'Training Time' : training_time,\n","            'Validation Time' : validation_time\n","        }\n","    )\n","    \n","print(\"\")\n","print(\"Training complete!\")\n","\n","print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":597},"id":"j-L4x00ScDxP","executionInfo":{"status":"error","timestamp":1666721530340,"user_tz":-540,"elapsed":928,"user":{"displayName":"Bini Kim","userId":"16545463548428762859"}},"outputId":"3cfb339a-71bc-43ea-c488-01e6307df9b7"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=======Epoch 1 / 10 =======\n","Training...\n"]},{"output_type":"stream","name":"stderr","text":["Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n","    send_bytes(obj)\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n","    self._send_bytes(m[offset:offset + size])\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n","    self._send(header + buf)\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n","    n = write(self._handle, buf)\n","BrokenPipeError: [Errno 32] Broken pipe\n"]},{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-32-9190973255f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m                             \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb_input_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                             labels = b_labels,)\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mtotal_train_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: forward() got an unexpected keyword argument 'labels'"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","#소수점 이하 두 자리로 부동 소수점을 표시\n","df_stats = pd.DataFrame(data=training_stats)\n","\n","#row index로 'epoch'사용\n","df_stats = df_stats.set_index('epoch')\n","\n","#column 헤더를 강제로 wrap\n","\n","#display the table.\n","df_stats"],"metadata":{"id":"Eh98Ng7OcZjg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666331894676,"user_tz":-540,"elapsed":62,"user":{"displayName":"Bini Kim","userId":"16545463548428762859"}},"outputId":"38cf8710-55b7-4346-b170-3413b00c22c0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n","epoch                                                                         \n","1           0.605396     0.273395            0.0       0:05:21         0:00:13\n","2           0.260440     0.291413            0.0       0:05:26         0:00:13\n","3           0.186792     0.268702            0.0       0:05:26         0:00:13\n","4           0.141295     0.424581            0.0       0:05:24         0:00:13\n","5           0.099672     0.356775            0.0       0:05:24         0:00:13\n","6           0.070747     0.390406            0.0       0:05:24         0:00:13\n","7           0.056141     0.339808            0.0       0:05:24         0:00:13\n","8           0.039732     0.342834            0.0       0:05:24         0:00:13\n","9           0.032159     0.341269            0.0       0:05:24         0:00:13\n","10          0.029775     0.352314            0.0       0:05:24         0:00:13"],"text/html":["\n","  <div id=\"df-3244e203-2460-4ee8-88b3-09537def3569\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Training Loss</th>\n","      <th>Valid. Loss</th>\n","      <th>Valid. Accur.</th>\n","      <th>Training Time</th>\n","      <th>Validation Time</th>\n","    </tr>\n","    <tr>\n","      <th>epoch</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>0.605396</td>\n","      <td>0.273395</td>\n","      <td>0.0</td>\n","      <td>0:05:21</td>\n","      <td>0:00:13</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.260440</td>\n","      <td>0.291413</td>\n","      <td>0.0</td>\n","      <td>0:05:26</td>\n","      <td>0:00:13</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.186792</td>\n","      <td>0.268702</td>\n","      <td>0.0</td>\n","      <td>0:05:26</td>\n","      <td>0:00:13</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.141295</td>\n","      <td>0.424581</td>\n","      <td>0.0</td>\n","      <td>0:05:24</td>\n","      <td>0:00:13</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.099672</td>\n","      <td>0.356775</td>\n","      <td>0.0</td>\n","      <td>0:05:24</td>\n","      <td>0:00:13</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.070747</td>\n","      <td>0.390406</td>\n","      <td>0.0</td>\n","      <td>0:05:24</td>\n","      <td>0:00:13</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.056141</td>\n","      <td>0.339808</td>\n","      <td>0.0</td>\n","      <td>0:05:24</td>\n","      <td>0:00:13</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0.039732</td>\n","      <td>0.342834</td>\n","      <td>0.0</td>\n","      <td>0:05:24</td>\n","      <td>0:00:13</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0.032159</td>\n","      <td>0.341269</td>\n","      <td>0.0</td>\n","      <td>0:05:24</td>\n","      <td>0:00:13</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>0.029775</td>\n","      <td>0.352314</td>\n","      <td>0.0</td>\n","      <td>0:05:24</td>\n","      <td>0:00:13</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3244e203-2460-4ee8-88b3-09537def3569')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3244e203-2460-4ee8-88b3-09537def3569 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3244e203-2460-4ee8-88b3-09537def3569');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","import seaborn as sns\n","\n","sns.set(style='darkgrid')\n","plt.rcParams[\"figure.figsize\"] = (12,6)\n","\n","plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n","plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n","\n","plt.title(\"[Grammar]Training & Validation Loss\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","plt.xticks([1, 2, 3, 4])\n","\n","plt.show()"],"metadata":{"id":"XkONdDsX1HGD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666331894677,"user_tz":-540,"elapsed":50,"user":{"displayName":"Bini Kim","userId":"16545463548428762859"}},"outputId":"4bd6f02a-106c-4af6-f9e2-a891543449b2"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 864x432 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["df_INNER_JOIN = pd.merge(test, submission, left_on='text_id', right_on='text_id', how='inner')\n","df_INNER_JOIN.drop(['cohesion','syntax','vocabulary','phraseology','conventions'], inplace=True, axis=1)\n","labels = df_INNER_JOIN\n","labels"],"metadata":{"id":"5nE_awQAHRsM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666331894679,"user_tz":-540,"elapsed":51,"user":{"displayName":"Bini Kim","userId":"16545463548428762859"}},"outputId":"b7ff2acd-85c8-4330-a272-404e32e4dbe3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["        text_id                                          full_text  grammar\n","0  0000C359D63E  when a person has no experience on a job their...      3.0\n","1  000BAD50D026  Do you think students would benefit from being...      3.0\n","2  00367BB2546B  Thomas Jefferson once states that \"it is wonde...      3.0"],"text/html":["\n","  <div id=\"df-aba87b62-7ab7-4e16-935f-8dff9e7a0e85\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text_id</th>\n","      <th>full_text</th>\n","      <th>grammar</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0000C359D63E</td>\n","      <td>when a person has no experience on a job their...</td>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>000BAD50D026</td>\n","      <td>Do you think students would benefit from being...</td>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>00367BB2546B</td>\n","      <td>Thomas Jefferson once states that \"it is wonde...</td>\n","      <td>3.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aba87b62-7ab7-4e16-935f-8dff9e7a0e85')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-aba87b62-7ab7-4e16-935f-8dff9e7a0e85 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-aba87b62-7ab7-4e16-935f-8dff9e7a0e85');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["import pandas as pd\n","#test = pd.read_csv('/kaggle/input/feedback-prize-english-language-learning/test.csv')\n","\n","#문장 수\n","print('Number of test sentences: {:,}\\n'.format(labels.shape[0]))\n","\n","#리스트 만들기\n","full_text = labels.full_text.values\n","labels = labels.grammar.values\n","\n","#모든 문장을 토큰화하고 토큰을 해당 단어 IDs에 매핑한다.\n","input_ids=[]\n","attention_masks = []\n","\n","for text in full_text:\n","    encoded_dict = tokenizer.encode_plus(\n","                    text,#문장을 encode\n","                    add_special_tokens = True, #[CLS][SEP]토큰 추가\n","                    max_length = 512, #모든 문장 자르고 채우기 \n","                    truncation=True,\n","                    pad_to_max_length = True,\n","                    return_attention_mask = True,#Attention mask 만들기\n","                    return_tensors = 'pt' #파이토치 텐서로 리턴\n","                    )\n","    input_ids.append(encoded_dict['input_ids'])\n","    attention_masks.append(encoded_dict['attention_mask'])\n","\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","labels = torch.tensor(labels)\n","\n","batch_size = 16\n","\n","prediction_data = TensorDataset(input_ids, attention_masks, labels)\n","prediction_sampler = SequentialSampler(prediction_data)\n","prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"],"metadata":{"id":"KZEKP8TP6Ozf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 테스트 셋 예측\n","print('Prediction labels for {:,} test sentences...'.format(len(input_ids)))\n","\n","# put model in evaluation mode\n","model.eval()\n","\n","#Tracking Variables\n","predictions, true_labels = [], []\n","\n","#predict\n","for batch in prediction_dataloader:\n","    #GPU에 Batch 넣기\n","    batch= tuple(t.to(device) for t in batch)\n","    \n","    #DataLoader에서 input 압축풀기\n","    b_input_ids, b_input_mask, b_labels = batch\n","    \n","    #모델에 기울기를 계산하거나 저장하지 않도록 지시하여 메모리를 절약하고\n","    #예측속도향상\n","    with torch.no_grad():\n","        #Forward pass, calculate logit predictions\n","        outputs = model(b_input_ids, token_type_ids=None,\n","                       attention_mask=b_input_mask)\n","    logits = outputs[0]\n","    \n","    #Logits, labels를 cpu로 옮기기\n","    logits = logits.detach().cpu().numpy()\n","    label_ids = b_labels.to('cpu').numpy()\n","    \n","    #Store predictions and true labels\n","    predictions.append(logits)\n","    true_labels.append(label_ids)\n","    \n","print('    완료. ')\n","print(predictions)\n","print(true_labels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DUeArJ_v6hx3","executionInfo":{"status":"error","timestamp":1666331894681,"user_tz":-540,"elapsed":51,"user":{"displayName":"Bini Kim","userId":"16545463548428762859"}},"outputId":"429b2594-bb81-4436-fba1-650356fe0c3e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Prediction labels for 3,911 test sentences...\n"]},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-cf7c0cf2f6ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprediction_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;31m#GPU에 Batch 넣기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'prediction_dataloader' is not defined"]}]},{"cell_type":"code","source":["grammar_submission = predictions[0]"],"metadata":{"id":"_iIZdW4-6j1A"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# cohesion"],"metadata":{"id":"_M3XLuuK6m1f"}},{"cell_type":"code","source":["train = pd.read_csv('/kaggle/input/feedback-prize-english-language-learning/train.csv')\n","test = pd.read_csv('/kaggle/input/feedback-prize-english-language-learning/test.csv')"],"metadata":{"id":"fSlS1CoI6lIq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#cohesion data만 사용하기 위해서 나머지 평가항목 컬럼은 드롭\n","train.drop(['grammar','syntax','vocabulary','phraseology','conventions'], inplace=True, axis=1)"],"metadata":{"id":"nWBCuDff6qpP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('Number of trainig sentences: {:,}\\n'.format(train.shape[0]))\n","train.sample(10)"],"metadata":{"id":"WA5O1AY36r-s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('Number of trainig sentences: {:,}\\n'.format(train.shape[0]))\n","train.sample(10)"],"metadata":{"id":"RLNTLEr16trR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import BertTokenizer\n","\n","print(\"Loading Bert Tokenizer...\")\n","tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)"],"metadata":{"id":"LOvCv0R96tta"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 모든 문장을 토큰화하고 토큰을 해당 단어 ID에 매핑\n","input_ids = []\n","attention_masks = []\n","\n","for text in full_text:\n","    encoded_dict = tokenizer.encode_plus(\n","                    text,#문장을 encode\n","                    add_special_tokens = True, #[CLS][SEP]토큰 추가\n","                    max_length = 512, #모든 문장 자르고 채우기 \n","                    # 'max_length'의 숫자는 어떻게 정하는 거지?\n","                    truncation=True,\n","                    pad_to_max_length = True,\n","                    return_attention_mask = True,#Attention mask 만들기\n","                    return_tensors = 'pt' #파이토치 텐서로 리턴\n","                    )\n","    # 인코딩된 문장을 목록에 추가\n","    input_ids.append(encoded_dict['input_ids'])\n","    \n","    # Attention mask\n","    attention_masks.append(encoded_dict['attention_mask'])\n","    \n","# 목록을 텐서로 변환\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","labels = torch.tensor(labels)\n","\n","# full_text 첫번째 문장을 IDs의 리스트로 출력해보기\n","print('Original: ', full_text[0])\n","print('Token IDs: ', input_ids[0])"],"metadata":{"id":"5Su1hFbU6tvs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import TensorDataset, random_split\n","# training inputs을 TensorDataset에 결합\n","dataset = TensorDataset(input_ids, attention_masks, labels)\n","\n","#90-10 train-validation split.\n","#각 세트에 포함할 샘플 수를 계산\n","train_size = int(0.9 * len(dataset))\n","val_size = len(dataset) - train_size\n","\n","#무작위로 샘플을 선택하여 데이터 세트를 나눈다.\n","train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n","\n","print('{:>5,} training samples'.format(train_size))\n","print('{:>5,} validation samples'.format(val_size))"],"metadata":{"id":"0HI3eohd6txx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","\n","#DataLoader는 훈련을 위한 배치크기를 알아야 하므로 지정함.\n","#Bert를 미세조정하기 위해 배치 사이즈 16/32 권장\n","batch_size = 16\n","\n","#training, validation 세트에 대한 DataLoader를 생성\n","#무작위 순서로 학습 샘플을 가져옴.\n","train_dataloader = DataLoader(\n","            train_dataset, # training sample\n","            sampler = RandomSampler(train_dataset), #배치를 랜덤으로 선택\n","            batch_size = batch_size #훈련을 이 배치 사이즈로 함.\n","        )\n","\n","#validation에서 순서가 중요하지 않아서 순서대로 진행함\n","valid_dataloader = DataLoader(\n","                val_dataset,\n","                sampler = SequentialSampler(val_dataset), # 배치를 순차적으로 꺼냄.\n","                batch_size = batch_size #이 배치 사이즈로 평가하기\n","        )"],"metadata":{"id":"V0-hsV-J6t0G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import BertForSequenceClassification, AdamW, BertConfig\n","\n","model = BertForSequenceClassification.from_pretrained(\n","        \"bert-base-uncased\", # 12레이어 버트 모델 사용 (uncased)\n","        num_labels = 1, #출력 레이블 수 (2진 분류의 경우 2)\n","        # grammar 점수가 9개라 9개 적음\n","        # 다중 클래스 작업의 경우 이 값을 늘릴 수 있다.\n","        output_attentions = False, #모델이 attention 가중치를 리턴하는지\n","        output_hidden_states = False, #모델이 hidden states를 리턴하는지\n","        #attention_probs_dropout_prob=0.4,\n","        #hidden_dropout_prob=0.4,\n",")\n","# GPU에서 이 모델을 실행하도록 pytorch에 지시\n","model.cuda()"],"metadata":{"id":"EvBg66ix6t2L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 모델의 모든 parameters를 튜플 목록으로 가져옴.\n","params = list(model.named_parameters())\n","\n","print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n","\n","print('==== Embedding Layer ====\\n')\n","\n","for p in params[0:5]:\n","    print(\"{:<55}{:12}\".format(p[0], str(tuple(p[1].size()))))\n","    \n","print('\\n==== First Transformer ====\\n')\n","\n","for p in params[5:21]:\n","    print(\"{:55}{:12}\".format(p[0], str(tuple(p[1].size()))))\n","    \n","print('\\n==== Output Layer ====\\n')\n","\n","for p in params[-4:]:\n","    print(\"{:55}{:12}\".format(p[0], str(tuple(p[1].size()))))"],"metadata":{"id":"EmdG25Li6t4d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 참고 : AdamW는 hugging face 라이브러리의 클래스임(pytorch와 반대)\n","# W = Weight Dacay Fix?\n","optimizer = AdamW(model.parameters(),\n","                 lr = 2e-5, #arg.learning_rate - 기본값은 5e-5이고 노트북에는 2e-5가 있다.\n","                 eps = 1e-8) #arg.adam_epsilon - 기본값은 1e-8"],"metadata":{"id":"xeOc8F016561"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import get_linear_schedule_with_warmup\n","\n","epochs = 10\n","# 총 훈련 단계 수는 [배치 수] X [에포크 수]\n","# (훈련 샘플의 수와 동일하지 않음)\n","total_steps = len(train_dataloader) * epochs\n","\n","# learning rate scheduler 만들기\n","scheduler = get_linear_schedule_with_warmup(optimizer,\n","                                           num_warmup_steps = 0,\n","                                           num_training_steps = total_steps)"],"metadata":{"id":"EI9SmNft6585"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","# 예측 vs 레이블의 정확도를 계산하는 함수\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"],"metadata":{"id":"nMNkElR_65_V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import time\n","import datetime\n","\n","def format_time(elapsed):\n","    #가까운 초로 반올림\n","    elapsed_rounded = int(round((elapsed)))\n","    #format as hh:mm:ss\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"],"metadata":{"id":"iwLE0AMh66Ba"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import random\n","import numpy as np\n","\n","#모든 곳에 seed 값을 설정하기\n","seed_val = 42\n","\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","# training , validation loss 같은 많은 수량을 저장\n","# validation accuracy, and timings.\n","training_stats = []\n","\n","# 전체 실행에 대한 총 훈련시간을 측정함\n","total_t0 = time.time()\n","\n","#for each epoch...\n","for epoch_i in range(0, epochs):\n","    print(\"\")\n","    print('=======Epoch {:} / {:} ======='.format(epoch_i+1, epochs))\n","    print(\"Training...\")\n","    \n","    # training epoch가 걸리는 시간을 측정\n","    t0 =time.time()\n","    \n","    # epoch의 전체 loss를 재설정\n","    total_train_loss = 0\n","    \n","    # 모델을 학습 모드로 전환 \n","    # train은 *모드*를 변경할 뿐 훈련을 *수행*하지 않음.\n","    # 'dropoout' / 'batchnorm' 레이어는 훈련 중에 다르게 작동함\n","    model.train()\n","    \n","    # 훈련 데이터의 각 batch에 대해\n","    for step, batch in enumerate(train_dataloader):\n","        #40개 batch마다 진행률이 업데이트됨\n","        if step % 40 == 0 and not step == 0:\n","            #경과시간을 분 단위로 계산함\n","            elapsed = format_time(time.time()-t0)\n","            #진행상황 보고\n","            print(' Batch {:>5,} of {:>5,}. Elapsed: {:}'.format(step, len(train_dataloader), elapsed))\n","    \n","        #DataLoader에서 훈련 batch의 압축을 푼다\n","        #Batch의 압축을 풀면서 각 텐서를 사용하여 GPU에 복사함\n","        # 'to' method\n","\n","        #'batch'에는 세 개의 pytorch 텐서가 포함되어 있음.\n","        # input ids\n","        # attention masks\n","        # labels\n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device, dtype=torch.float32)\n","\n","        # 모델 훈련을 수행하기 이전에 계산된 gradient는 지워야 함\n","        # backward pass : pytorch는 이 작업을 자동으로 수행하지 않는다.\n","        # gradient를 누적하는 것은 RNN을 훈련하는 동안 편리함\n","        model.zero_grad()\n","    \n","        # forward pass 수행 (정방향 전달)\n","        # 어떤 arguments에 따라 다른 수의 parameter를 return\n","        # arguments가 주어지고 flags가 설정됨\n","        # loss (label를 주었기 때문에) logits model\n","        # activation 전 출력\n","        loss, logits = model(b_input_ids,\n","                            token_type_ids=None,\n","                            attention_mask=b_input_mask,\n","                            labels = b_labels,\n","                            return_dict=False)\n","    \n","        #모든 Batch에 대한 훈련 loss를 누적하여 다음을 수행할 수 있다.\n","        # 마지막에 평균 loss를 계산함 loss는 다음을 포함하는 텐서이다.\n","        # single value; .item() function은 python 값을 return\n","        #print(loss.item(), type(loss.item()))\n","        total_train_loss += loss.item()\n","\n","        # backward pass로 gradients를 계산함\n","        loss.backward()\n","    \n","        # gradient 표준을 1.0으로 자름\n","        # \"exploding gradients\"문제에도 도움이 됨\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        # update parameters and take a step using the computed gradient\n","        # Optimizer는 \"업데이트 rule\"(parameter가 어떻게 학습률과 기울기에 따라 수정되는지)지시\n","        optimizer.step()\n","        \n","        #update the learnin rate.\n","        scheduler.step()\n","    \n","    # 모든 batch에 대한 평균 손실을 계산함\n","    avg_train_loss = total_train_loss / len(train_dataloader)\n","\n","    # 이 에포크가 얼마나 걸렸는지 측정\n","    training_time = format_time(time.time() - t0)\n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epoch took: {:}\".format(training_time))\n","    \n","    # ======validation======\n","    #각 training epoch를 완료 후 성능을 측정함\n","    # VALIDATION SET\n","    \n","    print(\"\")\n","    print(\"Running Validation...\")\n","    \n","    t0 = time.time()\n","    \n","    # 모델을 평가 모드에. dropout layer가 다르게 작동함\n","    model.eval()\n","    \n","    #Tracking variables\n","    total_eval_accuracy = 0\n","    total_eval_loss = 0\n","    nb_eval_steps = 0\n","    \n","    #Evaluate data for one epoch\n","    for batch in valid_dataloader:\n","        #DataLoader에서 training batch 압축 해제\n","        #batch의 압축을 풀면서 각 텐서를 GPU에 복사\n","        #\"to\"method.\n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device, dtype=torch.float32)\n","        \n","        #pytorch에게 compute 그래프를 구성하는동안 귀찮게 하지 말라고 하기\n","        #forward pass ; backprop (역전파) training에만 필요\n","        with torch.no_grad():\n","            \n","            #forward pass : logit predictions를 계산\n","            #token_type_ids는 \"segment ids\"와 동일\n","            # 2문장 작업에서 문장 1과 2를 구별\n","            \n","            #모델의 logits의 출력을 가져옴. \n","            #softmax 함수를 적용하기 전 값\n","            (loss, logits) = model(b_input_ids,\n","                                  token_type_ids=None,\n","                                  attention_mask=b_input_mask,\n","                                  labels=b_labels,\n","                                  return_dict=False)\n","        #validation loss를 누적\n","        total_eval_loss += loss.item()\n","        \n","        #logits, labels 는 CPU로 이동\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","        \n","        # test 문장 batch 정확도를 계산하고 모든 batch에 누적함\n","        total_eval_accuracy += flat_accuracy(logits, label_ids)\n","        \n","    # validation 실행에 대한 최종 정확도를 보고함.\n","    avg_val_accuracy = total_eval_accuracy / len(valid_dataloader)\n","    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n","    \n","    #모든 배치에 대한 평균 loss를 계산\n","    avg_val_loss = total_eval_loss / len(valid_dataloader)\n","    \n","    #validation실행에 걸린 시간을 측정\n","    validation_time = format_time(time.time()-t0)\n","    \n","    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n","    print(\"  Validation took: {:}\".format(validation_time))\n","    \n","    # epoch의 모든 통계를 기록\n","    training_stats.append(\n","        {\n","            'epoch': epoch_i+1,\n","            'Training Loss' : avg_train_loss,\n","            'Valid. Loss' : avg_val_loss,\n","            'Valid. Accur.' : avg_val_accuracy,\n","            'Training Time' : training_time,\n","            'Validation Time' : validation_time\n","        }\n","    )\n","    \n","print(\"\")\n","print(\"Training complete!\")\n","\n","print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"],"metadata":{"id":"NJ9qYvE266Dd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","df_stats = pd.DataFrame(data=training_stats)\n","df_stats = df_stats.set_index('epoch')\n","df_stats"],"metadata":{"id":"saCETjb966Fh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","import seaborn as sns\n","\n","sns.set(style='darkgrid')\n","plt.rcParams[\"figure.figsize\"] = (12,6)\n","\n","plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n","plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n","\n","plt.title(\"Training & Validation Loss\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","plt.xticks([1, 2, 3, 4])\n","\n","plt.show()"],"metadata":{"id":"LCwzP9UM66Hz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_INNER_JOIN = pd.merge(test, submission, left_on='text_id', right_on='text_id', how='inner')\n","df_INNER_JOIN.drop(['grammar','syntax','vocabulary','phraseology','conventions'], inplace=True, axis=1)\n","labels = df_INNER_JOIN\n","labels"],"metadata":{"id":"0h9-NDiw66Jn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","#test = pd.read_csv('/kaggle/input/feedback-prize-english-language-learning/test.csv')\n","\n","#문장 수\n","print('Number of test sentences: {:,}\\n'.format(labels.shape[0]))\n","\n","#리스트 만들기\n","full_text = labels.full_text.values\n","labels = labels.cohesion.values\n","\n","#모든 문장을 토큰화하고 토큰을 해당 단어 IDs에 매핑한다.\n","input_ids=[]\n","attention_masks = []\n","\n","for text in full_text:\n","    encoded_dict = tokenizer.encode_plus(\n","                    text,#문장을 encode\n","                    add_special_tokens = True, #[CLS][SEP]토큰 추가\n","                    max_length = 512, #모든 문장 자르고 채우기 \n","                    truncation=True,\n","                    pad_to_max_length = True,\n","                    return_attention_mask = True,#Attention mask 만들기\n","                    return_tensors = 'pt' #파이토치 텐서로 리턴\n","                    )\n","    input_ids.append(encoded_dict['input_ids'])\n","    attention_masks.append(encoded_dict['attention_mask'])\n","\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","labels = torch.tensor(labels)\n","\n","batch_size = 16\n","\n","prediction_data = TensorDataset(input_ids, attention_masks, labels)\n","prediction_sampler = SequentialSampler(prediction_data)\n","prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"],"metadata":{"id":"o1_6NC8y66Lr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 테스트 셋 예측\n","print('Prediction labels for {:,} test sentences...'.format(len(input_ids)))\n","\n","# put model in evaluation mode\n","model.eval()\n","\n","#Tracking Variables\n","predictions, true_labels = [], []\n","\n","#predict\n","for batch in prediction_dataloader:\n","    #GPU에 Batch 넣기\n","    batch= tuple(t.to(device) for t in batch)\n","    \n","    #DataLoader에서 input 압축풀기\n","    b_input_ids, b_input_mask, b_labels = batch\n","    \n","    #모델에 기울기를 계산하거나 저장하지 않도록 지시하여 메모리를 절약하고\n","    #예측속도향상\n","    with torch.no_grad():\n","        #Forward pass, calculate logit predictions\n","        outputs = model(b_input_ids, token_type_ids=None,\n","                       attention_mask=b_input_mask)\n","    logits = outputs[0]\n","    \n","    #Logits, labels를 cpu로 옮기기\n","    logits = logits.detach().cpu().numpy()\n","    label_ids = b_labels.to('cpu').numpy()\n","    \n","    #Store predictions and true labels\n","    predictions.append(logits)\n","    true_labels.append(label_ids)\n","    \n","print('    완료. ')\n","print(predictions)\n","print(true_labels)"],"metadata":{"id":"AGIquFjS66Nh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cohesion_submission = predictions[0]"],"metadata":{"id":"3S4cGiQB7iup"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Syntax"],"metadata":{"id":"-JzMFe4Z7kU6"}},{"cell_type":"code","source":["train = pd.read_csv('/kaggle/input/feedback-prize-english-language-learning/train.csv')\n","test = pd.read_csv('/kaggle/input/feedback-prize-english-language-learning/test.csv')\n","#cohesion data만 사용하기 위해서 나머지 평가항목 컬럼은 드롭\n","train.drop(['cohesion','grammar','vocabulary','phraseology','conventions'], inplace=True, axis=1)\n","print('Number of trainig sentences: {:,}\\n'.format(train.shape[0]))\n","train.sample(10)"],"metadata":{"id":"owO3OD_l7jpt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Get the lists of sentences and their labels.\n","full_text = train.full_text.values\n","labels = train.syntax.values\n","\n","from transformers import BertTokenizer\n","\n","print(\"Loading Bert Tokenizer...\")\n","tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)"],"metadata":{"id":"POq2b-JS7pvT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 모든 문장을 토큰화하고 토큰을 해당 단어 ID에 매핑\n","input_ids = []\n","attention_masks = []\n","\n","for text in full_text:\n","    encoded_dict = tokenizer.encode_plus(\n","                    text,#문장을 encode\n","                    add_special_tokens = True, #[CLS][SEP]토큰 추가\n","                    max_length = 512, #모든 문장 자르고 채우기 \n","                    truncation=True,\n","                    pad_to_max_length = True,\n","                    return_attention_mask = True,#Attention mask 만들기\n","                    return_tensors = 'pt' #파이토치 텐서로 리턴\n","                    )\n","    # 인코딩된 문장을 목록에 추가\n","    input_ids.append(encoded_dict['input_ids'])\n","    \n","    # Attention mask\n","    attention_masks.append(encoded_dict['attention_mask'])\n","    \n","# 목록을 텐서로 변환\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","labels = torch.tensor(labels)\n","\n","# full_text 첫번째 문장을 IDs의 리스트로 출력해보기\n","print('Original: ', full_text[0])\n","print('Token IDs: ', input_ids[0])"],"metadata":{"id":"mlbc_vmU7px3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import TensorDataset, random_split\n","# training inputs을 TensorDataset에 결합\n","dataset = TensorDataset(input_ids, attention_masks, labels)\n","\n","#90-10 train-validation split.\n","#각 세트에 포함할 샘플 수를 계산\n","train_size = int(0.9 * len(dataset))\n","val_size = len(dataset) - train_size\n","\n","#무작위로 샘플을 선택하여 데이터 세트를 나눈다.\n","train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n","\n","print('{:>5,} training samples'.format(train_size))\n","print('{:>5,} validation samples'.format(val_size))"],"metadata":{"id":"DI3SUSrm7pz8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","\n","batch_size = 16\n","\n","train_dataloader = DataLoader(\n","            train_dataset, # training sample\n","            sampler = RandomSampler(train_dataset), #배치를 랜덤으로 선택\n","            batch_size = batch_size #훈련을 이 배치 사이즈로 함.\n","        )\n","\n","valid_dataloader = DataLoader(\n","                val_dataset,\n","                sampler = SequentialSampler(val_dataset), # 배치를 순차적으로 꺼냄.\n","                batch_size = batch_size #이 배치 사이즈로 평가하기\n","        )\n","\n","from transformers import BertForSequenceClassification, AdamW, BertConfig\n","\n","model = BertForSequenceClassification.from_pretrained(\n","        \"bert-base-uncased\", # 12레이어 버트 모델 사용 (uncased)\n","        num_labels = 1, \n","        output_attentions = False, #모델이 attention 가중치를 리턴하는지\n","        output_hidden_states = False, #모델이 hidden states를 리턴하는지\n","        #attention_probs_dropout_prob=0.4,\n","        #hidden_dropout_prob=0.4,\n",")\n","\n","model.cuda()"],"metadata":{"id":"IJ-BFnF57p2B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["optimizer = AdamW(model.parameters(),\n","                 lr = 2e-5, #arg.learning_rate - 기본값은 5e-5이고 노트북에는 2e-5가 있다.\n","                 eps = 1e-8) #arg.adam_epsilon - 기본값은 1e-8"],"metadata":{"id":"XUWl7CW77p33"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import get_linear_schedule_with_warmup\n","\n","epochs = 10\n","\n","total_steps = len(train_dataloader) * epochs\n","\n","scheduler = get_linear_schedule_with_warmup(optimizer,\n","                                           num_warmup_steps = 0,\n","                                           num_training_steps = total_steps)"],"metadata":{"id":"_XUG0NrT7p57"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","# 예측 vs 레이블의 정확도를 계산하는 함수\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"],"metadata":{"id":"jR0Ht8FM70IY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import time\n","import datetime\n","\n","def format_time(elapsed):\n","    #가까운 초로 반올림\n","    elapsed_rounded = int(round((elapsed)))\n","    #format as hh:mm:ss\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"],"metadata":{"id":"MAvkXSmO70Ku"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import random\n","import numpy as np\n","\n","#모든 곳에 seed 값을 설정하기\n","seed_val = 42\n","\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","# training , validation loss 같은 많은 수량을 저장\n","# validation accuracy, and timings.\n","training_stats = []\n","\n","# 전체 실행에 대한 총 훈련시간을 측정함\n","total_t0 = time.time()\n","\n","#for each epoch...\n","for epoch_i in range(0, epochs):\n","    print(\"\")\n","    print('=======Epoch {:} / {:} ======='.format(epoch_i+1, epochs))\n","    print(\"Training...\")\n","    \n","    # training epoch가 걸리는 시간을 측정\n","    t0 =time.time()\n","    \n","    # epoch의 전체 loss를 재설정\n","    total_train_loss = 0\n","    \n","    # 모델을 학습 모드로 전환 \n","    # train은 *모드*를 변경할 뿐 훈련을 *수행*하지 않음.\n","    # 'dropoout' / 'batchnorm' 레이어는 훈련 중에 다르게 작동함\n","    model.train()\n","    \n","    # 훈련 데이터의 각 batch에 대해\n","    for step, batch in enumerate(train_dataloader):\n","        #40개 batch마다 진행률이 업데이트됨\n","        if step % 40 == 0 and not step == 0:\n","            #경과시간을 분 단위로 계산함\n","            elapsed = format_time(time.time()-t0)\n","            #진행상황 보고\n","            print(' Batch {:>5,} of {:>5,}. Elapsed: {:}'.format(step, len(train_dataloader), elapsed))\n","    \n","        #DataLoader에서 훈련 batch의 압축을 푼다\n","        #Batch의 압축을 풀면서 각 텐서를 사용하여 GPU에 복사함\n","        # 'to' method\n","\n","        #'batch'에는 세 개의 pytorch 텐서가 포함되어 있음.\n","        # input ids\n","        # attention masks\n","        # labels\n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device, dtype=torch.float32)\n","\n","        # 모델 훈련을 수행하기 이전에 계산된 gradient는 지워야 함\n","        # backward pass : pytorch는 이 작업을 자동으로 수행하지 않는다.\n","        # gradient를 누적하는 것은 RNN을 훈련하는 동안 편리함\n","        model.zero_grad()\n","    \n","        # forward pass 수행 (정방향 전달)\n","        # 어떤 arguments에 따라 다른 수의 parameter를 return\n","        # arguments가 주어지고 flags가 설정됨\n","        # loss (label를 주었기 때문에) logits model\n","        # activation 전 출력\n","        loss, logits = model(b_input_ids,\n","                            token_type_ids=None,\n","                            attention_mask=b_input_mask,\n","                            labels = b_labels,\n","                            return_dict=False)\n","    \n","        #모든 Batch에 대한 훈련 loss를 누적하여 다음을 수행할 수 있다.\n","        # 마지막에 평균 loss를 계산함 loss는 다음을 포함하는 텐서이다.\n","        # single value; .item() function은 python 값을 return\n","        #print(loss.item(), type(loss.item()))\n","        total_train_loss += loss.item()\n","\n","        # backward pass로 gradients를 계산함\n","        loss.backward()\n","    \n","        # gradient 표준을 1.0으로 자름\n","        # \"exploding gradients\"문제에도 도움이 됨\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        # update parameters and take a step using the computed gradient\n","        # Optimizer는 \"업데이트 rule\"(parameter가 어떻게 학습률과 기울기에 따라 수정되는지)지시\n","        optimizer.step()\n","        \n","        #update the learnin rate.\n","        scheduler.step()\n","    \n","    # 모든 batch에 대한 평균 손실을 계산함\n","    avg_train_loss = total_train_loss / len(train_dataloader)\n","\n","    # 이 에포크가 얼마나 걸렸는지 측정\n","    training_time = format_time(time.time() - t0)\n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epoch took: {:}\".format(training_time))\n","    \n","    # ======validation======\n","    #각 training epoch를 완료 후 성능을 측정함\n","    # VALIDATION SET\n","    \n","    print(\"\")\n","    print(\"Running Validation...\")\n","    \n","    t0 = time.time()\n","    \n","    # 모델을 평가 모드에. dropout layer가 다르게 작동함\n","    model.eval()\n","    \n","    #Tracking variables\n","    total_eval_accuracy = 0\n","    total_eval_loss = 0\n","    nb_eval_steps = 0\n","    \n","    #Evaluate data for one epoch\n","    for batch in valid_dataloader:\n","        #DataLoader에서 training batch 압축 해제\n","        #batch의 압축을 풀면서 각 텐서를 GPU에 복사\n","        #\"to\"method.\n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device, dtype=torch.float32)\n","        \n","        #pytorch에게 compute 그래프를 구성하는동안 귀찮게 하지 말라고 하기\n","        #forward pass ; backprop (역전파) training에만 필요\n","        with torch.no_grad():\n","            \n","            #forward pass : logit predictions를 계산\n","            #token_type_ids는 \"segment ids\"와 동일\n","            # 2문장 작업에서 문장 1과 2를 구별\n","            \n","            #모델의 logits의 출력을 가져옴. \n","            #softmax 함수를 적용하기 전 값\n","            (loss, logits) = model(b_input_ids,\n","                                  token_type_ids=None,\n","                                  attention_mask=b_input_mask,\n","                                  labels=b_labels,\n","                                  return_dict=False)\n","        #validation loss를 누적\n","        total_eval_loss += loss.item()\n","        \n","        #logits, labels 는 CPU로 이동\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","        \n","        # test 문장 batch 정확도를 계산하고 모든 batch에 누적함\n","        total_eval_accuracy += flat_accuracy(logits, label_ids)\n","        \n","    # validation 실행에 대한 최종 정확도를 보고함.\n","    avg_val_accuracy = total_eval_accuracy / len(valid_dataloader)\n","    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n","    \n","    #모든 배치에 대한 평균 loss를 계산\n","    avg_val_loss = total_eval_loss / len(valid_dataloader)\n","    \n","    #validation실행에 걸린 시간을 측정\n","    validation_time = format_time(time.time()-t0)\n","    \n","    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n","    print(\"  Validation took: {:}\".format(validation_time))\n","    \n","    # epoch의 모든 통계를 기록\n","    training_stats.append(\n","        {\n","            'epoch': epoch_i+1,\n","            'Training Loss' : avg_train_loss,\n","            'Valid. Loss' : avg_val_loss,\n","            'Valid. Accur.' : avg_val_accuracy,\n","            'Training Time' : training_time,\n","            'Validation Time' : validation_time\n","        }\n","    )\n","    \n","print(\"\")\n","print(\"Training complete!\")\n","\n","print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"],"metadata":{"id":"wYU35NXp70My"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","df_stats = pd.DataFrame(data=training_stats)\n","df_stats = df_stats.set_index('epoch')\n","df_stats"],"metadata":{"id":"ySt3aNtP70O4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","import seaborn as sns\n","\n","sns.set(style='darkgrid')\n","plt.rcParams[\"figure.figsize\"] = (12,6)\n","\n","plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n","plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n","\n","plt.title(\"[cohesion]Training & Validation Loss\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","plt.xticks([1, 2, 3, 4])\n","\n","plt.show()"],"metadata":{"id":"l5pumH_b70RC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_INNER_JOIN = pd.merge(test, submission, left_on='text_id', right_on='text_id', how='inner')\n","df_INNER_JOIN.drop(['grammar','cohesion','vocabulary','phraseology','conventions'], inplace=True, axis=1)\n","labels = df_INNER_JOIN\n","labels"],"metadata":{"id":"aJXGV1Sv79F0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","#test = pd.read_csv('/kaggle/input/feedback-prize-english-language-learning/test.csv')\n","\n","#문장 수\n","print('Number of test sentences: {:,}\\n'.format(labels.shape[0]))\n","\n","#리스트 만들기\n","full_text = labels.full_text.values\n","labels = labels.syntax.values\n","\n","#모든 문장을 토큰화하고 토큰을 해당 단어 IDs에 매핑한다.\n","input_ids=[]\n","attention_masks = []\n","\n","for text in full_text:\n","    encoded_dict = tokenizer.encode_plus(\n","                    text,#문장을 encode\n","                    add_special_tokens = True, #[CLS][SEP]토큰 추가\n","                    max_length = 512, #모든 문장 자르고 채우기 \n","                    truncation=True,\n","                    pad_to_max_length = True,\n","                    return_attention_mask = True,#Attention mask 만들기\n","                    return_tensors = 'pt' #파이토치 텐서로 리턴\n","                    )\n","    input_ids.append(encoded_dict['input_ids'])\n","    attention_masks.append(encoded_dict['attention_mask'])\n","\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","labels = torch.tensor(labels)\n","\n","batch_size = 16\n","\n","prediction_data = TensorDataset(input_ids, attention_masks, labels)\n","prediction_sampler = SequentialSampler(prediction_data)\n","prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"],"metadata":{"id":"v2qhtphR79Hp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 테스트 셋 예측\n","print('Prediction labels for {:,} test sentences...'.format(len(input_ids)))\n","\n","# put model in evaluation mode\n","model.eval()\n","\n","#Tracking Variables\n","predictions, true_labels = [], []\n","\n","#predict\n","for batch in prediction_dataloader:\n","    #GPU에 Batch 넣기\n","    batch= tuple(t.to(device) for t in batch)\n","    \n","    #DataLoader에서 input 압축풀기\n","    b_input_ids, b_input_mask, b_labels = batch\n","    \n","    #모델에 기울기를 계산하거나 저장하지 않도록 지시하여 메모리를 절약하고\n","    #예측속도향상\n","    with torch.no_grad():\n","        #Forward pass, calculate logit predictions\n","        outputs = model(b_input_ids, token_type_ids=None,\n","                       attention_mask=b_input_mask)\n","    logits = outputs[0]\n","    \n","    #Logits, labels를 cpu로 옮기기\n","    logits = logits.detach().cpu().numpy()\n","    label_ids = b_labels.to('cpu').numpy()\n","    \n","    #Store predictions and true labels\n","    predictions.append(logits)\n","    true_labels.append(label_ids)\n","    \n","print('    완료. ')\n","print(predictions)\n","print(true_labels)"],"metadata":{"id":"ylucnuxS79J-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["syntax_submission = predictions[0]"],"metadata":{"id":"VEEW08p479L1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Vacabulary"],"metadata":{"id":"knnf03y38IGf"}},{"cell_type":"code","source":["train = pd.read_csv('/kaggle/input/feedback-prize-english-language-learning/train.csv')\n","test = pd.read_csv('/kaggle/input/feedback-prize-english-language-learning/test.csv')\n","#cohesion data만 사용하기 위해서 나머지 평가항목 컬럼은 드롭\n","train.drop(['cohesion','grammar','syntax','phraseology','conventions'], inplace=True, axis=1)\n","print('Number of trainig sentences: {:,}\\n'.format(train.shape[0]))\n","train.sample(10)"],"metadata":{"id":"57Gu-uUh70TD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Get the lists of sentences and their labels.\n","full_text = train.full_text.values\n","labels = train.vocabulary.values\n","\n","from transformers import BertTokenizer\n","\n","print(\"Loading Bert Tokenizer...\")\n","tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)"],"metadata":{"id":"6XoJfaLU70VT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 모든 문장을 토큰화하고 토큰을 해당 단어 ID에 매핑\n","input_ids = []\n","attention_masks = []\n","\n","for text in full_text:\n","    encoded_dict = tokenizer.encode_plus(\n","                    text,#문장을 encode\n","                    add_special_tokens = True, #[CLS][SEP]토큰 추가\n","                    max_length = 512, #모든 문장 자르고 채우기 \n","                    # 'max_length'의 숫자는 어떻게 정하는 거지?\n","                    truncation=True,\n","                    pad_to_max_length = True,\n","                    return_attention_mask = True,#Attention mask 만들기\n","                    return_tensors = 'pt' #파이토치 텐서로 리턴\n","                    )\n","    # 인코딩된 문장을 목록에 추가\n","    input_ids.append(encoded_dict['input_ids'])\n","    \n","    # Attention mask\n","    attention_masks.append(encoded_dict['attention_mask'])\n","    \n","# 목록을 텐서로 변환\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","labels = torch.tensor(labels)\n","\n","# full_text 첫번째 문장을 IDs의 리스트로 출력해보기\n","print('Original: ', full_text[0])\n","print('Token IDs: ', input_ids[0])"],"metadata":{"id":"xQdGtAg88OZv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import TensorDataset, random_split\n","# training inputs을 TensorDataset에 결합\n","dataset = TensorDataset(input_ids, attention_masks, labels)\n","\n","#90-10 train-validation split.\n","#각 세트에 포함할 샘플 수를 계산\n","train_size = int(0.9 * len(dataset))\n","val_size = len(dataset) - train_size\n","\n","#무작위로 샘플을 선택하여 데이터 세트를 나눈다.\n","train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n","\n","print('{:>5,} training samples'.format(train_size))\n","print('{:>5,} validation samples'.format(val_size))"],"metadata":{"id":"VF28pVRk8Ve9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","\n","batch_size = 16\n","\n","train_dataloader = DataLoader(\n","            train_dataset, # training sample\n","            sampler = RandomSampler(train_dataset), #배치를 랜덤으로 선택\n","            batch_size = batch_size #훈련을 이 배치 사이즈로 함.\n","        )\n","\n","valid_dataloader = DataLoader(\n","                val_dataset,\n","                sampler = SequentialSampler(val_dataset), # 배치를 순차적으로 꺼냄.\n","                batch_size = batch_size #이 배치 사이즈로 평가하기\n","        )\n","\n","from transformers import BertForSequenceClassification, AdamW, BertConfig\n","\n","model = BertForSequenceClassification.from_pretrained(\n","        \"bert-base-uncased\", # 12레이어 버트 모델 사용 (uncased)\n","        num_labels = 1, \n","        output_attentions = False, #모델이 attention 가중치를 리턴하는지\n","        output_hidden_states = False, #모델이 hidden states를 리턴하는지\n","        #attention_probs_dropout_prob=0.4,\n","        #hidden_dropout_prob=0.4,\n",")\n","\n","model.cuda()"],"metadata":{"id":"dxFIryDr8XU_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["optimizer = AdamW(model.parameters(),\n","                 lr = 2e-5, #arg.learning_rate - 기본값은 5e-5이고 노트북에는 2e-5가 있다.\n","                 eps = 1e-8) #arg.adam_epsilon - 기본값은 1e-8"],"metadata":{"id":"0Bo0CADv8ZYn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import get_linear_schedule_with_warmup\n","\n","epochs = 10\n","\n","total_steps = len(train_dataloader) * epochs\n","\n","scheduler = get_linear_schedule_with_warmup(optimizer,\n","                                           num_warmup_steps = 0,\n","                                           num_training_steps = total_steps)"],"metadata":{"id":"2_tpO_MP8aOH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","# 예측 vs 레이블의 정확도를 계산하는 함수\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n","\n","import time\n","import datetime\n","\n","def format_time(elapsed):\n","    #가까운 초로 반올림\n","    elapsed_rounded = int(round((elapsed)))\n","    #format as hh:mm:ss\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"],"metadata":{"id":"dXtTR0z08aU4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import random\n","import numpy as np\n","\n","#모든 곳에 seed 값을 설정하기\n","seed_val = 42\n","\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","# training , validation loss 같은 많은 수량을 저장\n","# validation accuracy, and timings.\n","training_stats = []\n","\n","# 전체 실행에 대한 총 훈련시간을 측정함\n","total_t0 = time.time()\n","\n","#for each epoch...\n","for epoch_i in range(0, epochs):\n","    print(\"\")\n","    print('=======Epoch {:} / {:} ======='.format(epoch_i+1, epochs))\n","    print(\"Training...\")\n","    \n","    # training epoch가 걸리는 시간을 측정\n","    t0 =time.time()\n","    \n","    # epoch의 전체 loss를 재설정\n","    total_train_loss = 0\n","    \n","    # 모델을 학습 모드로 전환 \n","    # train은 *모드*를 변경할 뿐 훈련을 *수행*하지 않음.\n","    # 'dropoout' / 'batchnorm' 레이어는 훈련 중에 다르게 작동함\n","    model.train()\n","    \n","    # 훈련 데이터의 각 batch에 대해\n","    for step, batch in enumerate(train_dataloader):\n","        #40개 batch마다 진행률이 업데이트됨\n","        if step % 40 == 0 and not step == 0:\n","            #경과시간을 분 단위로 계산함\n","            elapsed = format_time(time.time()-t0)\n","            #진행상황 보고\n","            print(' Batch {:>5,} of {:>5,}. Elapsed: {:}'.format(step, len(train_dataloader), elapsed))\n","    \n","        #DataLoader에서 훈련 batch의 압축을 푼다\n","        #Batch의 압축을 풀면서 각 텐서를 사용하여 GPU에 복사함\n","        # 'to' method\n","\n","        #'batch'에는 세 개의 pytorch 텐서가 포함되어 있음.\n","        # input ids\n","        # attention masks\n","        # labels\n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device, dtype=torch.float32)\n","\n","        # 모델 훈련을 수행하기 이전에 계산된 gradient는 지워야 함\n","        # backward pass : pytorch는 이 작업을 자동으로 수행하지 않는다.\n","        # gradient를 누적하는 것은 RNN을 훈련하는 동안 편리함\n","        model.zero_grad()\n","    \n","        # forward pass 수행 (정방향 전달)\n","        # 어떤 arguments에 따라 다른 수의 parameter를 return\n","        # arguments가 주어지고 flags가 설정됨\n","        # loss (label를 주었기 때문에) logits model\n","        # activation 전 출력\n","        loss, logits = model(b_input_ids,\n","                            token_type_ids=None,\n","                            attention_mask=b_input_mask,\n","                            labels = b_labels,\n","                            return_dict=False)\n","    \n","        #모든 Batch에 대한 훈련 loss를 누적하여 다음을 수행할 수 있다.\n","        # 마지막에 평균 loss를 계산함 loss는 다음을 포함하는 텐서이다.\n","        # single value; .item() function은 python 값을 return\n","        #print(loss.item(), type(loss.item()))\n","        total_train_loss += loss.item()\n","\n","        # backward pass로 gradients를 계산함\n","        loss.backward()\n","    \n","        # gradient 표준을 1.0으로 자름\n","        # \"exploding gradients\"문제에도 도움이 됨\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        # update parameters and take a step using the computed gradient\n","        # Optimizer는 \"업데이트 rule\"(parameter가 어떻게 학습률과 기울기에 따라 수정되는지)지시\n","        optimizer.step()\n","        \n","        #update the learnin rate.\n","        scheduler.step()\n","    \n","    # 모든 batch에 대한 평균 손실을 계산함\n","    avg_train_loss = total_train_loss / len(train_dataloader)\n","\n","    # 이 에포크가 얼마나 걸렸는지 측정\n","    training_time = format_time(time.time() - t0)\n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epoch took: {:}\".format(training_time))\n","    \n","    # ======validation======\n","    #각 training epoch를 완료 후 성능을 측정함\n","    # VALIDATION SET\n","    \n","    print(\"\")\n","    print(\"Running Validation...\")\n","    \n","    t0 = time.time()\n","    \n","    # 모델을 평가 모드에. dropout layer가 다르게 작동함\n","    model.eval()\n","    \n","    #Tracking variables\n","    total_eval_accuracy = 0\n","    total_eval_loss = 0\n","    nb_eval_steps = 0\n","    \n","    #Evaluate data for one epoch\n","    for batch in valid_dataloader:\n","        #DataLoader에서 training batch 압축 해제\n","        #batch의 압축을 풀면서 각 텐서를 GPU에 복사\n","        #\"to\"method.\n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device, dtype=torch.float32)\n","        \n","        #pytorch에게 compute 그래프를 구성하는동안 귀찮게 하지 말라고 하기\n","        #forward pass ; backprop (역전파) training에만 필요\n","        with torch.no_grad():\n","            \n","            #forward pass : logit predictions를 계산\n","            #token_type_ids는 \"segment ids\"와 동일\n","            # 2문장 작업에서 문장 1과 2를 구별\n","            \n","            #모델의 logits의 출력을 가져옴. \n","            #softmax 함수를 적용하기 전 값\n","            (loss, logits) = model(b_input_ids,\n","                                  token_type_ids=None,\n","                                  attention_mask=b_input_mask,\n","                                  labels=b_labels,\n","                                  return_dict=False)\n","        #validation loss를 누적\n","        total_eval_loss += loss.item()\n","        \n","        #logits, labels 는 CPU로 이동\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","        \n","        # test 문장 batch 정확도를 계산하고 모든 batch에 누적함\n","        total_eval_accuracy += flat_accuracy(logits, label_ids)\n","        \n","    # validation 실행에 대한 최종 정확도를 보고함.\n","    avg_val_accuracy = total_eval_accuracy / len(valid_dataloader)\n","    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n","    \n","    #모든 배치에 대한 평균 loss를 계산\n","    avg_val_loss = total_eval_loss / len(valid_dataloader)\n","    \n","    #validation실행에 걸린 시간을 측정\n","    validation_time = format_time(time.time()-t0)\n","    \n","    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n","    print(\"  Validation took: {:}\".format(validation_time))\n","    \n","    # epoch의 모든 통계를 기록\n","    training_stats.append(\n","        {\n","            'epoch': epoch_i+1,\n","            'Training Loss' : avg_train_loss,\n","            'Valid. Loss' : avg_val_loss,\n","            'Valid. Accur.' : avg_val_accuracy,\n","            'Training Time' : training_time,\n","            'Validation Time' : validation_time\n","        }\n","    )\n","    \n","print(\"\")\n","print(\"Training complete!\")\n","\n","print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"],"metadata":{"id":"mwutC_6P8gNu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","df_stats = pd.DataFrame(data=training_stats)\n","df_stats = df_stats.set_index('epoch')\n","df_stats"],"metadata":{"id":"stbGe2v58goT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","import seaborn as sns\n","\n","sns.set(style='darkgrid')\n","plt.rcParams[\"figure.figsize\"] = (12,6)\n","\n","plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n","plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n","\n","plt.title(\"[vocabulary]Training & Validation Loss\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","plt.xticks([1, 2, 3, 4])\n","\n","plt.show()"],"metadata":{"id":"ei9ZOsV38gqX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_INNER_JOIN = pd.merge(test, submission, left_on='text_id', right_on='text_id', how='inner')\n","df_INNER_JOIN.drop(['grammar','cohesion','syntax','phraseology','conventions'], inplace=True, axis=1)\n","labels = df_INNER_JOIN\n","labels"],"metadata":{"id":"fah5l1wu8gsd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","#test = pd.read_csv('/kaggle/input/feedback-prize-english-language-learning/test.csv')\n","\n","#문장 수\n","print('Number of test sentences: {:,}\\n'.format(labels.shape[0]))\n","\n","#리스트 만들기\n","full_text = labels.full_text.values\n","labels = labels.vocabulary.values\n","\n","#모든 문장을 토큰화하고 토큰을 해당 단어 IDs에 매핑한다.\n","input_ids=[]\n","attention_masks = []\n","\n","for text in full_text:\n","    encoded_dict = tokenizer.encode_plus(\n","                    text,#문장을 encode\n","                    add_special_tokens = True, #[CLS][SEP]토큰 추가\n","                    max_length = 256, #모든 문장 자르고 채우기 \n","                    truncation=True,\n","                    pad_to_max_length = True,\n","                    return_attention_mask = True,#Attention mask 만들기\n","                    return_tensors = 'pt' #파이토치 텐서로 리턴\n","                    )\n","    input_ids.append(encoded_dict['input_ids'])\n","    attention_masks.append(encoded_dict['attention_mask'])\n","\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","labels = torch.tensor(labels)\n","\n","batch_size = 16\n","\n","prediction_data = TensorDataset(input_ids, attention_masks, labels)\n","prediction_sampler = SequentialSampler(prediction_data)\n","prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"],"metadata":{"id":"AFj_cfax8gui"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 테스트 셋 예측\n","print('Prediction labels for {:,} test sentences...'.format(len(input_ids)))\n","\n","# put model in evaluation mode\n","model.eval()\n","\n","#Tracking Variables\n","predictions, true_labels = [], []\n","\n","#predict\n","for batch in prediction_dataloader:\n","    #GPU에 Batch 넣기\n","    batch= tuple(t.to(device) for t in batch)\n","    \n","    #DataLoader에서 input 압축풀기\n","    b_input_ids, b_input_mask, b_labels = batch\n","    \n","    #모델에 기울기를 계산하거나 저장하지 않도록 지시하여 메모리를 절약하고\n","    #예측속도향상\n","    with torch.no_grad():\n","        #Forward pass, calculate logit predictions\n","        outputs = model(b_input_ids, token_type_ids=None,\n","                       attention_mask=b_input_mask)\n","    logits = outputs[0]\n","    \n","    #Logits, labels를 cpu로 옮기기\n","    logits = logits.detach().cpu().numpy()\n","    label_ids = b_labels.to('cpu').numpy()\n","    \n","    #Store predictions and true labels\n","    predictions.append(logits)\n","    true_labels.append(label_ids)\n","    \n","print('    완료. ')\n","print(predictions)\n","print(true_labels)"],"metadata":{"id":"7D3lnvdp8gwn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vocab_submission = predictions[0]"],"metadata":{"id":"eddzSM4V8gyt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# phraseology"],"metadata":{"id":"LZamL-2E9JXU"}},{"cell_type":"code","source":["train = pd.read_csv('/kaggle/input/feedback-prize-english-language-learning/train.csv')\n","test = pd.read_csv('/kaggle/input/feedback-prize-english-language-learning/test.csv')\n","#cohesion data만 사용하기 위해서 나머지 평가항목 컬럼은 드롭\n","train.drop(['cohesion','grammar','syntax','vocabulary','conventions'], inplace=True, axis=1)\n","print('Number of trainig sentences: {:,}\\n'.format(train.shape[0]))\n","train.sample(10)"],"metadata":{"id":"s0hnNxWH9Iim"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Get the lists of sentences and their labels.\n","full_text = train.full_text.values\n","labels = train.phraseology.values\n","\n","from transformers import BertTokenizer\n","\n","print(\"Loading Bert Tokenizer...\")\n","tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)"],"metadata":{"id":"tdkw-jtV9PfF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 모든 문장을 토큰화하고 토큰을 해당 단어 ID에 매핑\n","input_ids = []\n","attention_masks = []\n","\n","for text in full_text:\n","    encoded_dict = tokenizer.encode_plus(\n","                    text,#문장을 encode\n","                    add_special_tokens = True, #[CLS][SEP]토큰 추가\n","                    max_length = 256, #모든 문장 자르고 채우기 \n","                    # 'max_length'의 숫자는 어떻게 정하는 거지?\n","                    truncation=True,\n","                    pad_to_max_length = True,\n","                    return_attention_mask = True,#Attention mask 만들기\n","                    return_tensors = 'pt' #파이토치 텐서로 리턴\n","                    )\n","    # 인코딩된 문장을 목록에 추가\n","    input_ids.append(encoded_dict['input_ids'])\n","    \n","    # Attention mask\n","    attention_masks.append(encoded_dict['attention_mask'])\n","    \n","# 목록을 텐서로 변환\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","labels = torch.tensor(labels)\n","\n","# full_text 첫번째 문장을 IDs의 리스트로 출력해보기\n","print('Original: ', full_text[0])\n","print('Token IDs: ', input_ids[0])"],"metadata":{"id":"vUSE2AxC9RPh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import TensorDataset, random_split\n","# training inputs을 TensorDataset에 결합\n","dataset = TensorDataset(input_ids, attention_masks, labels)\n","\n","#90-10 train-validation split.\n","#각 세트에 포함할 샘플 수를 계산\n","train_size = int(0.9 * len(dataset))\n","val_size = len(dataset) - train_size\n","\n","#무작위로 샘플을 선택하여 데이터 세트를 나눈다.\n","train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n","\n","print('{:>5,} training samples'.format(train_size))\n","print('{:>5,} validation samples'.format(val_size))"],"metadata":{"id":"A3Ao76sT9TeM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","\n","batch_size = 16\n","\n","train_dataloader = DataLoader(\n","            train_dataset, # training sample\n","            sampler = RandomSampler(train_dataset), #배치를 랜덤으로 선택\n","            batch_size = batch_size #훈련을 이 배치 사이즈로 함.\n","        )\n","\n","valid_dataloader = DataLoader(\n","                val_dataset,\n","                sampler = SequentialSampler(val_dataset), # 배치를 순차적으로 꺼냄.\n","                batch_size = batch_size #이 배치 사이즈로 평가하기\n","        )\n","\n","from transformers import BertForSequenceClassification, AdamW, BertConfig\n","\n","model = BertForSequenceClassification.from_pretrained(\n","        \"bert-base-uncased\", # 12레이어 버트 모델 사용 (uncased)\n","        num_labels = 1, \n","        output_attentions = False, #모델이 attention 가중치를 리턴하는지\n","        output_hidden_states = False, #모델이 hidden states를 리턴하는지\n","        #attention_probs_dropout_prob=0.4,\n","        #hidden_dropout_prob=0.4,\n",")\n","\n","model.cuda()"],"metadata":{"id":"hexgqiDy9Vch"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["optimizer = AdamW(model.parameters(),\n","                 lr = 2e-5, #arg.learning_rate - 기본값은 5e-5이고 노트북에는 2e-5가 있다.\n","                 eps = 1e-8) #arg.adam_epsilon - 기본값은 1e-8"],"metadata":{"id":"LiNcF3fP9YLT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import get_linear_schedule_with_warmup\n","\n","epochs = 10\n","\n","total_steps = len(train_dataloader) * epochs\n","\n","scheduler = get_linear_schedule_with_warmup(optimizer,\n","                                           num_warmup_steps = 0,\n","                                           num_training_steps = total_steps)"],"metadata":{"id":"HGq06LsI9Zkj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","# 예측 vs 레이블의 정확도를 계산하는 함수\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n","\n","import time\n","import datetime\n","\n","def format_time(elapsed):\n","    #가까운 초로 반올림\n","    elapsed_rounded = int(round((elapsed)))\n","    #format as hh:mm:ss\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"],"metadata":{"id":"KrTYmxrW9bgl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import random\n","import numpy as np\n","\n","#모든 곳에 seed 값을 설정하기\n","seed_val = 42\n","\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","# training , validation loss 같은 많은 수량을 저장\n","# validation accuracy, and timings.\n","training_stats = []\n","\n","# 전체 실행에 대한 총 훈련시간을 측정함\n","total_t0 = time.time()\n","\n","#for each epoch...\n","for epoch_i in range(0, epochs):\n","    print(\"\")\n","    print('=======Epoch {:} / {:} ======='.format(epoch_i+1, epochs))\n","    print(\"Training...\")\n","    \n","    # training epoch가 걸리는 시간을 측정\n","    t0 =time.time()\n","    \n","    # epoch의 전체 loss를 재설정\n","    total_train_loss = 0\n","    \n","    # 모델을 학습 모드로 전환 \n","    # train은 *모드*를 변경할 뿐 훈련을 *수행*하지 않음.\n","    # 'dropoout' / 'batchnorm' 레이어는 훈련 중에 다르게 작동함\n","    model.train()\n","    \n","    # 훈련 데이터의 각 batch에 대해\n","    for step, batch in enumerate(train_dataloader):\n","        #40개 batch마다 진행률이 업데이트됨\n","        if step % 40 == 0 and not step == 0:\n","            #경과시간을 분 단위로 계산함\n","            elapsed = format_time(time.time()-t0)\n","            #진행상황 보고\n","            print(' Batch {:>5,} of {:>5,}. Elapsed: {:}'.format(step, len(train_dataloader), elapsed))\n","    \n","        #DataLoader에서 훈련 batch의 압축을 푼다\n","        #Batch의 압축을 풀면서 각 텐서를 사용하여 GPU에 복사함\n","        # 'to' method\n","\n","        #'batch'에는 세 개의 pytorch 텐서가 포함되어 있음.\n","        # input ids\n","        # attention masks\n","        # labels\n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device, dtype=torch.float32)\n","\n","        # 모델 훈련을 수행하기 이전에 계산된 gradient는 지워야 함\n","        # backward pass : pytorch는 이 작업을 자동으로 수행하지 않는다.\n","        # gradient를 누적하는 것은 RNN을 훈련하는 동안 편리함\n","        model.zero_grad()\n","    \n","        # forward pass 수행 (정방향 전달)\n","        # 어떤 arguments에 따라 다른 수의 parameter를 return\n","        # arguments가 주어지고 flags가 설정됨\n","        # loss (label를 주었기 때문에) logits model\n","        # activation 전 출력\n","        loss, logits = model(b_input_ids,\n","                            token_type_ids=None,\n","                            attention_mask=b_input_mask,\n","                            labels = b_labels,\n","                            return_dict=False)\n","    \n","        #모든 Batch에 대한 훈련 loss를 누적하여 다음을 수행할 수 있다.\n","        # 마지막에 평균 loss를 계산함 loss는 다음을 포함하는 텐서이다.\n","        # single value; .item() function은 python 값을 return\n","        #print(loss.item(), type(loss.item()))\n","        total_train_loss += loss.item()\n","\n","        # backward pass로 gradients를 계산함\n","        loss.backward()\n","    \n","        # gradient 표준을 1.0으로 자름\n","        # \"exploding gradients\"문제에도 도움이 됨\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        # update parameters and take a step using the computed gradient\n","        # Optimizer는 \"업데이트 rule\"(parameter가 어떻게 학습률과 기울기에 따라 수정되는지)지시\n","        optimizer.step()\n","        \n","        #update the learnin rate.\n","        scheduler.step()\n","    \n","    # 모든 batch에 대한 평균 손실을 계산함\n","    avg_train_loss = total_train_loss / len(train_dataloader)\n","\n","    # 이 에포크가 얼마나 걸렸는지 측정\n","    training_time = format_time(time.time() - t0)\n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epoch took: {:}\".format(training_time))\n","    \n","    # ======validation======\n","    #각 training epoch를 완료 후 성능을 측정함\n","    # VALIDATION SET\n","    \n","    print(\"\")\n","    print(\"Running Validation...\")\n","    \n","    t0 = time.time()\n","    \n","    # 모델을 평가 모드에. dropout layer가 다르게 작동함\n","    model.eval()\n","    \n","    #Tracking variables\n","    total_eval_accuracy = 0\n","    total_eval_loss = 0\n","    nb_eval_steps = 0\n","    \n","    #Evaluate data for one epoch\n","    for batch in valid_dataloader:\n","        #DataLoader에서 training batch 압축 해제\n","        #batch의 압축을 풀면서 각 텐서를 GPU에 복사\n","        #\"to\"method.\n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device, dtype=torch.float32)\n","        \n","        #pytorch에게 compute 그래프를 구성하는동안 귀찮게 하지 말라고 하기\n","        #forward pass ; backprop (역전파) training에만 필요\n","        with torch.no_grad():\n","            \n","            #forward pass : logit predictions를 계산\n","            #token_type_ids는 \"segment ids\"와 동일\n","            # 2문장 작업에서 문장 1과 2를 구별\n","            \n","            #모델의 logits의 출력을 가져옴. \n","            #softmax 함수를 적용하기 전 값\n","            (loss, logits) = model(b_input_ids,\n","                                  token_type_ids=None,\n","                                  attention_mask=b_input_mask,\n","                                  labels=b_labels,\n","                                  return_dict=False)\n","        #validation loss를 누적\n","        total_eval_loss += loss.item()\n","        \n","        #logits, labels 는 CPU로 이동\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","        \n","        # test 문장 batch 정확도를 계산하고 모든 batch에 누적함\n","        total_eval_accuracy += flat_accuracy(logits, label_ids)\n","        \n","    # validation 실행에 대한 최종 정확도를 보고함.\n","    avg_val_accuracy = total_eval_accuracy / len(valid_dataloader)\n","    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n","    \n","    #모든 배치에 대한 평균 loss를 계산\n","    avg_val_loss = total_eval_loss / len(valid_dataloader)\n","    \n","    #validation실행에 걸린 시간을 측정\n","    validation_time = format_time(time.time()-t0)\n","    \n","    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n","    print(\"  Validation took: {:}\".format(validation_time))\n","    \n","    # epoch의 모든 통계를 기록\n","    training_stats.append(\n","        {\n","            'epoch': epoch_i+1,\n","            'Training Loss' : avg_train_loss,\n","            'Valid. Loss' : avg_val_loss,\n","            'Valid. Accur.' : avg_val_accuracy,\n","            'Training Time' : training_time,\n","            'Validation Time' : validation_time\n","        }\n","    )\n","    \n","print(\"\")\n","print(\"Training complete!\")\n","\n","print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"],"metadata":{"id":"pSlIMaNo9dVt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","df_stats = pd.DataFrame(data=training_stats)\n","df_stats = df_stats.set_index('epoch')\n","df_stats"],"metadata":{"id":"x8Fbk4fy9dtE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","import seaborn as sns\n","\n","sns.set(style='darkgrid')\n","plt.rcParams[\"figure.figsize\"] = (12,6)\n","\n","plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n","plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n","\n","plt.title(\"[Phrase]Training & Validation Loss\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","plt.xticks([1, 2, 3, 4])\n","\n","plt.show()"],"metadata":{"id":"_3Movi0W9dx1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_INNER_JOIN = pd.merge(test, submission, left_on='text_id', right_on='text_id', how='inner')\n","df_INNER_JOIN.drop(['grammar','cohesion','syntax','vocabulary','conventions'], inplace=True, axis=1)\n","labels = df_INNER_JOIN\n","labels"],"metadata":{"id":"G8wo11V39d0M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","#test = pd.read_csv('/kaggle/input/feedback-prize-english-language-learning/test.csv')\n","\n","#문장 수\n","print('Number of test sentences: {:,}\\n'.format(labels.shape[0]))\n","\n","#리스트 만들기\n","full_text = labels.full_text.values\n","labels = labels.phraseology.values\n","\n","#모든 문장을 토큰화하고 토큰을 해당 단어 IDs에 매핑한다.\n","input_ids=[]\n","attention_masks = []\n","\n","for text in full_text:\n","    encoded_dict = tokenizer.encode_plus(\n","                    text,#문장을 encode\n","                    add_special_tokens = True, #[CLS][SEP]토큰 추가\n","                    max_length = 512, #모든 문장 자르고 채우기 \n","                    truncation=True,\n","                    pad_to_max_length = True,\n","                    return_attention_mask = True,#Attention mask 만들기\n","                    return_tensors = 'pt' #파이토치 텐서로 리턴\n","                    )\n","    input_ids.append(encoded_dict['input_ids'])\n","    attention_masks.append(encoded_dict['attention_mask'])\n","\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","labels = torch.tensor(labels)\n","\n","batch_size = 16\n","\n","prediction_data = TensorDataset(input_ids, attention_masks, labels)\n","prediction_sampler = SequentialSampler(prediction_data)\n","prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"],"metadata":{"id":"kK9R_Krt9d2R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 테스트 셋 예측\n","print('Prediction labels for {:,} test sentences...'.format(len(input_ids)))\n","\n","# put model in evaluation mode\n","model.eval()\n","\n","#Tracking Variables\n","predictions, true_labels = [], []\n","\n","#predict\n","for batch in prediction_dataloader:\n","    #GPU에 Batch 넣기\n","    batch= tuple(t.to(device) for t in batch)\n","    \n","    #DataLoader에서 input 압축풀기\n","    b_input_ids, b_input_mask, b_labels = batch\n","    \n","    #모델에 기울기를 계산하거나 저장하지 않도록 지시하여 메모리를 절약하고\n","    #예측속도향상\n","    with torch.no_grad():\n","        #Forward pass, calculate logit predictions\n","        outputs = model(b_input_ids, token_type_ids=None,\n","                       attention_mask=b_input_mask)\n","    logits = outputs[0]\n","    \n","    #Logits, labels를 cpu로 옮기기\n","    logits = logits.detach().cpu().numpy()\n","    label_ids = b_labels.to('cpu').numpy()\n","    \n","    #Store predictions and true labels\n","    predictions.append(logits)\n","    true_labels.append(label_ids)\n","    \n","print('    완료. ')\n","print(predictions)\n","print(true_labels)"],"metadata":{"id":"3RIxNbEn9uVe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["phrase_submission = predictions[0]"],"metadata":{"id":"FjDKgLgp9zdk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Conventions"],"metadata":{"id":"iECVR8hM92N4"}},{"cell_type":"code","source":["train = pd.read_csv('/kaggle/input/feedback-prize-english-language-learning/train.csv')\n","test = pd.read_csv('/kaggle/input/feedback-prize-english-language-learning/test.csv')\n","#cohesion data만 사용하기 위해서 나머지 평가항목 컬럼은 드롭\n","train.drop(['cohesion','grammar','syntax','vocabulary','phraseology'], inplace=True, axis=1)\n","print('Number of trainig sentences: {:,}\\n'.format(train.shape[0]))\n","train.sample(10)"],"metadata":{"id":"Rwq4VoHQ9027"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Get the lists of sentences and their labels.\n","full_text = train.full_text.values\n","labels = train.conventions.values\n","\n","from transformers import BertTokenizer\n","\n","print(\"Loading Bert Tokenizer...\")\n","tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)"],"metadata":{"id":"hiegZqGk9-R_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 모든 문장을 토큰화하고 토큰을 해당 단어 ID에 매핑\n","input_ids = []\n","attention_masks = []\n","\n","for text in full_text:\n","    encoded_dict = tokenizer.encode_plus(\n","                    text,#문장을 encode\n","                    add_special_tokens = True, #[CLS][SEP]토큰 추가\n","                    max_length = 512, #모든 문장 자르고 채우기 \n","                    # 'max_length'의 숫자는 어떻게 정하는 거지?\n","                    truncation=True,\n","                    pad_to_max_length = True,\n","                    return_attention_mask = True,#Attention mask 만들기\n","                    return_tensors = 'pt' #파이토치 텐서로 리턴\n","                    )\n","    # 인코딩된 문장을 목록에 추가\n","    input_ids.append(encoded_dict['input_ids'])\n","    \n","    # Attention mask\n","    attention_masks.append(encoded_dict['attention_mask'])\n","    \n","# 목록을 텐서로 변환\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","labels = torch.tensor(labels)\n","\n","# full_text 첫번째 문장을 IDs의 리스트로 출력해보기\n","print('Original: ', full_text[0])\n","print('Token IDs: ', input_ids[0])"],"metadata":{"id":"f-V3Jix0-AFq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import TensorDataset, random_split\n","# training inputs을 TensorDataset에 결합\n","dataset = TensorDataset(input_ids, attention_masks, labels)\n","\n","#90-10 train-validation split.\n","#각 세트에 포함할 샘플 수를 계산\n","train_size = int(0.9 * len(dataset))\n","val_size = len(dataset) - train_size\n","\n","#무작위로 샘플을 선택하여 데이터 세트를 나눈다.\n","train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n","\n","print('{:>5,} training samples'.format(train_size))\n","print('{:>5,} validation samples'.format(val_size))"],"metadata":{"id":"Sfe32VA7-CxY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","\n","batch_size = 16\n","\n","train_dataloader = DataLoader(\n","            train_dataset, # training sample\n","            sampler = RandomSampler(train_dataset), #배치를 랜덤으로 선택\n","            batch_size = batch_size #훈련을 이 배치 사이즈로 함.\n","        )\n","\n","valid_dataloader = DataLoader(\n","                val_dataset,\n","                sampler = SequentialSampler(val_dataset), # 배치를 순차적으로 꺼냄.\n","                batch_size = batch_size #이 배치 사이즈로 평가하기\n","        )\n","\n","from transformers import BertForSequenceClassification, AdamW, BertConfig\n","\n","model = BertForSequenceClassification.from_pretrained(\n","        \"bert-base-uncased\", # 12레이어 버트 모델 사용 (uncased)\n","        num_labels = 1, \n","        output_attentions = False, #모델이 attention 가중치를 리턴하는지\n","        output_hidden_states = False, #모델이 hidden states를 리턴하는지\n","        #attention_probs_dropout_prob=0.4,\n","        #hidden_dropout_prob=0.4,\n",")\n","\n","model.cuda()"],"metadata":{"id":"4ivIcY4--FVj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["optimizer = AdamW(model.parameters(),\n","                 lr = 2e-5, #arg.learning_rate - 기본값은 5e-5이고 노트북에는 2e-5가 있다.\n","                 eps = 1e-8) #arg.adam_epsilon - 기본값은 1e-8"],"metadata":{"id":"Ztm7j318-JNy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import get_linear_schedule_with_warmup\n","\n","epochs = 10\n","\n","total_steps = len(train_dataloader) * epochs\n","\n","scheduler = get_linear_schedule_with_warmup(optimizer,\n","                                           num_warmup_steps = 0,\n","                                           num_training_steps = total_steps)"],"metadata":{"id":"aNC1kpNq-KnI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","# 예측 vs 레이블의 정확도를 계산하는 함수\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n","\n","import time\n","import datetime\n","\n","def format_time(elapsed):\n","    #가까운 초로 반올림\n","    elapsed_rounded = int(round((elapsed)))\n","    #format as hh:mm:ss\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"],"metadata":{"id":"tTleudvh-L7y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import random\n","import numpy as np\n","\n","#모든 곳에 seed 값을 설정하기\n","seed_val = 42\n","\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","# training , validation loss 같은 많은 수량을 저장\n","# validation accuracy, and timings.\n","training_stats = []\n","\n","# 전체 실행에 대한 총 훈련시간을 측정함\n","total_t0 = time.time()\n","\n","#for each epoch...\n","for epoch_i in range(0, epochs):\n","    print(\"\")\n","    print('=======Epoch {:} / {:} ======='.format(epoch_i+1, epochs))\n","    print(\"Training...\")\n","    \n","    # training epoch가 걸리는 시간을 측정\n","    t0 =time.time()\n","    \n","    # epoch의 전체 loss를 재설정\n","    total_train_loss = 0\n","    \n","    # 모델을 학습 모드로 전환 \n","    # train은 *모드*를 변경할 뿐 훈련을 *수행*하지 않음.\n","    # 'dropoout' / 'batchnorm' 레이어는 훈련 중에 다르게 작동함\n","    model.train()\n","    \n","    # 훈련 데이터의 각 batch에 대해\n","    for step, batch in enumerate(train_dataloader):\n","        #40개 batch마다 진행률이 업데이트됨\n","        if step % 40 == 0 and not step == 0:\n","            #경과시간을 분 단위로 계산함\n","            elapsed = format_time(time.time()-t0)\n","            #진행상황 보고\n","            print(' Batch {:>5,} of {:>5,}. Elapsed: {:}'.format(step, len(train_dataloader), elapsed))\n","    \n","        #DataLoader에서 훈련 batch의 압축을 푼다\n","        #Batch의 압축을 풀면서 각 텐서를 사용하여 GPU에 복사함\n","        # 'to' method\n","\n","        #'batch'에는 세 개의 pytorch 텐서가 포함되어 있음.\n","        # input ids\n","        # attention masks\n","        # labels\n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device, dtype=torch.float32)\n","\n","        # 모델 훈련을 수행하기 이전에 계산된 gradient는 지워야 함\n","        # backward pass : pytorch는 이 작업을 자동으로 수행하지 않는다.\n","        # gradient를 누적하는 것은 RNN을 훈련하는 동안 편리함\n","        model.zero_grad()\n","    \n","        # forward pass 수행 (정방향 전달)\n","        # 어떤 arguments에 따라 다른 수의 parameter를 return\n","        # arguments가 주어지고 flags가 설정됨\n","        # loss (label를 주었기 때문에) logits model\n","        # activation 전 출력\n","        loss, logits = model(b_input_ids,\n","                            token_type_ids=None,\n","                            attention_mask=b_input_mask,\n","                            labels = b_labels,\n","                            return_dict=False)\n","    \n","        #모든 Batch에 대한 훈련 loss를 누적하여 다음을 수행할 수 있다.\n","        # 마지막에 평균 loss를 계산함 loss는 다음을 포함하는 텐서이다.\n","        # single value; .item() function은 python 값을 return\n","        #print(loss.item(), type(loss.item()))\n","        total_train_loss += loss.item()\n","\n","        # backward pass로 gradients를 계산함\n","        loss.backward()\n","    \n","        # gradient 표준을 1.0으로 자름\n","        # \"exploding gradients\"문제에도 도움이 됨\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        # update parameters and take a step using the computed gradient\n","        # Optimizer는 \"업데이트 rule\"(parameter가 어떻게 학습률과 기울기에 따라 수정되는지)지시\n","        optimizer.step()\n","        \n","        #update the learnin rate.\n","        scheduler.step()\n","    \n","    # 모든 batch에 대한 평균 손실을 계산함\n","    avg_train_loss = total_train_loss / len(train_dataloader)\n","\n","    # 이 에포크가 얼마나 걸렸는지 측정\n","    training_time = format_time(time.time() - t0)\n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epoch took: {:}\".format(training_time))\n","    \n","    # ======validation======\n","    #각 training epoch를 완료 후 성능을 측정함\n","    # VALIDATION SET\n","    \n","    print(\"\")\n","    print(\"Running Validation...\")\n","    \n","    t0 = time.time()\n","    \n","    # 모델을 평가 모드에. dropout layer가 다르게 작동함\n","    model.eval()\n","    \n","    #Tracking variables\n","    total_eval_accuracy = 0\n","    total_eval_loss = 0\n","    nb_eval_steps = 0\n","    \n","    #Evaluate data for one epoch\n","    for batch in valid_dataloader:\n","        #DataLoader에서 training batch 압축 해제\n","        #batch의 압축을 풀면서 각 텐서를 GPU에 복사\n","        #\"to\"method.\n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device, dtype=torch.float32)\n","        \n","        #pytorch에게 compute 그래프를 구성하는동안 귀찮게 하지 말라고 하기\n","        #forward pass ; backprop (역전파) training에만 필요\n","        with torch.no_grad():\n","            \n","            #forward pass : logit predictions를 계산\n","            #token_type_ids는 \"segment ids\"와 동일\n","            # 2문장 작업에서 문장 1과 2를 구별\n","            \n","            #모델의 logits의 출력을 가져옴. \n","            #softmax 함수를 적용하기 전 값\n","            (loss, logits) = model(b_input_ids,\n","                                  token_type_ids=None,\n","                                  attention_mask=b_input_mask,\n","                                  labels=b_labels,\n","                                  return_dict=False)\n","        #validation loss를 누적\n","        total_eval_loss += loss.item()\n","        \n","        #logits, labels 는 CPU로 이동\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","        \n","        # test 문장 batch 정확도를 계산하고 모든 batch에 누적함\n","        total_eval_accuracy += flat_accuracy(logits, label_ids)\n","        \n","    # validation 실행에 대한 최종 정확도를 보고함.\n","    avg_val_accuracy = total_eval_accuracy / len(valid_dataloader)\n","    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n","    \n","    #모든 배치에 대한 평균 loss를 계산\n","    avg_val_loss = total_eval_loss / len(valid_dataloader)\n","    \n","    #validation실행에 걸린 시간을 측정\n","    validation_time = format_time(time.time()-t0)\n","    \n","    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n","    print(\"  Validation took: {:}\".format(validation_time))\n","    \n","    # epoch의 모든 통계를 기록\n","    training_stats.append(\n","        {\n","            'epoch': epoch_i+1,\n","            'Training Loss' : avg_train_loss,\n","            'Valid. Loss' : avg_val_loss,\n","            'Valid. Accur.' : avg_val_accuracy,\n","            'Training Time' : training_time,\n","            'Validation Time' : validation_time\n","        }\n","    )\n","    \n","print(\"\")\n","print(\"Training complete!\")\n","\n","print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"],"metadata":{"id":"-2FZzpwT-Nyz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","df_stats = pd.DataFrame(data=training_stats)\n","df_stats = df_stats.set_index('epoch')\n","df_stats"],"metadata":{"id":"BE3tuYxt-PDu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","import seaborn as sns\n","\n","sns.set(style='darkgrid')\n","plt.rcParams[\"figure.figsize\"] = (12,6)\n","\n","plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n","plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n","\n","plt.title(\"Training & Validation Loss\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","plt.xticks([1, 2, 3, 4])\n","\n","plt.show()"],"metadata":{"id":"sieWh99m-RSM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"AFzksOM5-TUH"},"execution_count":null,"outputs":[]}]}